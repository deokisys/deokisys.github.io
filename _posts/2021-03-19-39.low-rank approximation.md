---
layout: post
title: 39.low-rank approximation
categories: AI boost
tags: [ai,boost,인수분해,kernel,decomposition]
toc : true
math : true
---

# 강의 복습 내용
- low-rank approximation for model compression


## 얻은 지식

-----

## low-rank approximation for model compression
- 인수분해는 왜할까(factorization)

### tree maps
- matrix(tensor)는 데이터 모델링 도구
- matrix(tensor)는 linear transformation
  - 선형변형이 가능하다.
- terminology
  - 각각의 의미를 화살표따라 이해하기

- gaussian eliminatino
  - basis는?
- decomposition,factorization은 비슷한 느낌
  - filter,kernel,matrix,tensor,low-rank

### kernel method
- 커널?
  - 핵심
- 중요한 부분을 보기위해 계산하는것
  - 복잡해진 계산을 간단하게 해주기도한다.
- depth-wise separable convlution
  - regular convolution보다 적은 계산
  - 근사한 값을 얻을 수 있따.


### matrix decomposition
- nxm->nxr rxm으로 분해하는것
- 예
  - user x movies -> user x d, d x movies
- eigenvalue decomposition
  - 아이겐은뭐냐
    - 변환할때 방향은 보존, 길이만 변하는것
  - ![그림](https://user-images.githubusercontent.com/24247768/111762497-6ac2bb80-88e4-11eb-977a-320325aec8dd.png)
    - 아이겐벡터.아이겐벨류.아이겐벡터-1
- single value decomposition(SVD)
  - EVD의 일반화한거
  - svd를 제곱하면 evd가된다.

### tensor decomposition
- 3차원 이상의것
- 직접계산은 정신건강에 안좋다고한다.
- canonicla polyadic decompositino
  - core tensor와 sub spce3개로 분리하는 방법
  - rank1짜리의 선형결합으로 표현하는 방법
  - ![그림](https://user-images.githubusercontent.com/24247768/111762597-862dc680-88e4-11eb-9368-1d9235a216bf.png)
- tensor의 구성 분석(TCA tensor components analysis)
  - time, neurons, trials와 같이 분석
  - 실제 딥러닝은 이런식은 아니라고한다.

### tensor decomposition on network compression
- mobile net
- depth-wise separable convolution

-------

## 돌아보기
- 병렬처리 라이브러리
  - ray
- 압축 라이브러리
  - tflite

----

## 좀더 찾아보기
- SVD
- EVD

-----

## 피어세션 정리
- 조교님과의 만남
- 필터와 커널의 차이?
  - 커널은 2d, 필터는 3d
  - [참고1](https://data-science-hi.tistory.com/128)
  - 필터를 decomposition(커널을 decomposition)
  - 커널은 전체적인 사이즈, 필터는 그런 커널들이 입력 채널마다 생긴 weigh의 합들
  - [참고2](https://towardsdatascience.com/a-comprehensive-introduction-to-different-types-of-convolutions-in-deep-learning-669281e58215)
- 쿨백라이블러 knowledge distillation loss
  - [참고1](https://light-tree.tistory.com/196)
  - [참고2](https://wikidocs.net/60572)

------

## 마스터 클래스
- 소비자가 되지 말아라
- 멘토활용
  - 아는것을 확증받는거x
  - 모르는것을 물어볼때, 자기의견을 이야기(객관화x)
- 회사에 자기를 맞추지마라


--------

## 회고
- 피어세션이 오프라인이었으면하는 아쉬움
  - 강의를 쉬는시간같을때 바로 질문 할 수 있는 소통시간이 있었으면 더욱 풍부했을거 같다.
  - 아무래도 온라인이기때문에 만나는 시간이 정해졌어야 해서 아쉬웠다.
- 자극을 주는사람이 되기보다 모두에게 자극만 받고 갑니다.

