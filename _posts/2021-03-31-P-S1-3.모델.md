---
layout: post
title: P-S1-3.모델
categories: AI boostP
tags: [ai,boost,모델,module,nn.module]
toc : true
math : true
---

## 강의확인
- 모델링

### pytorch로 모델링
- `import torch.nn as nn`
- `import torch.nn.functional as F`
- pytorch는 nn.Moule클래스를 따른다.
  - nn.Conv2d()로 모델 정보를 선언
  - ConvNd는 stride,padding,dilationn,groups,padding_mode,output_padding,in_channels,out_channels,kernel_size가 있다.
- `__init__`은?
  - `print(a)`하거나 `list(a.modules())`로 확인가능
  - 저장소라고 생각
  - 저장소에 있는것들을 forward에서 사용
- `forward`는?
  - 모델이 호출되었을때 실행되는함수
  - `a(x)`는 `a.forward(x)`와 같음
  - nn.Module을 상속받으면 forward를 가진다.
- 모듈내부의 실제 tensor 파라메터 확인법
  - `a.state_dict()` - 딕셔너리다!
  - `list(a.parameters())`
- 각 파라메터도 변수를 가진다.
  - data
  - grad(미분값 gradient)
  - requires_grad


### pretrained
- 적절한 pretrained 모델을 찾는게 중요
  - 원하는 목표와 유사하면  backbone을 freeze하여 분류기만 학습하는게 가능



-----

## 피어세션
- EfficientNet이 좀더 효율 좋다는 의견



-----

## 오늘 한일
- 모델 darknet 구현
  - 그림과 실제 코드와 예시모형을 보고 따라 작성해보기

## 어떻게 했는지
- 그림과 예시 모형을 보았지만, 어떻게 구현을 해야할지 막막했다.
- 기본제공 코드와 참고하는 코드를 따라 보면서 분석하여 작성하였다.


## 좋았던 점
- nn.Module에 대한 자세한 내용을 들을 수 있었다.
- 모델을 구성하는것을 다시 건드릴수 있어서 좋았다.


## 아쉬운 점
- 아무래도 점점 피어세션이 매일 바뀌다보니 불편한점이 나오는것 같다.
- 단순히 그림만 보고 모델을 구현하는데 어려움이 느껴진다.
- 어느정도 파라메터가 있으면 가능할거 같지만, residual같은 부분이 나오면 머리속에서 제대로 설계가 안나온다....

