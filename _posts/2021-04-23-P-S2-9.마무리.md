---
layout: post
title: P-S2-9.마무리
categories: AI boostP
tags: [ai,boost]
toc : true
math : true
---

## 피어세션 
- kortok이라는 모듈로 형태소단위로 사용하는것
  - https://github.com/kakaobrain/kortok
  - bert이다.
- 본인 발표
  - [SEP]의 special 토큰으로서와 plain토큰으로 있을때 차이가 있었다.
  - roberta는 구분자에 두개
  - roberta의 <s>문장1</s><s>문장2</s>로 나뉜것 확인
  - 데이터 불균형이 아쉽다.
- 앙상블은 corelation이 낮음
  - inference할때 모델 돌려서 앙상블로 보팅
- 소프트의 하드 보팅 차이가 있다.
  - 하드보팅이 좀더 좋게 평가되었다.
- koelecktra, roberta

## 마스터세션

### 리더보드1등
- 모델
  - xlm-roberta-large
  - xlm-roberta-large + lstm(단일으로는 약해도 앙상블로 성능향상을 이뤘다)
  - koelectra
- hard voting 앙상블

### 토론왕
- out of distribution 
  - 아예 처음보는것도 잘못된 분류로 넘기는게 요즘 모델에서는 confidence가 높아서 무조건 하나의 클래스를 확률이 높게 나온다고한다.

### 마스터클래스
- 앙상블쓰는거 좋았다.
- focal loss를 적용한게 좋았다.
- random mask가 좋았다.
  - fine tunning할때 mask를 적용하지 않는다고 한다. 따로 해줘야한다.
  - 실무에서도 사용한다고한다.
- random switching
  - 문장을 둘로 잘라서 위치 변경하는것
- entity사이가 길면 둘의 사이를 줄이는것도 좋은 아이디어
- 논문은 친절하지 않다.
- 토론은 실패한 정보라도 이런 실패를 고치면서 발전되는것이다.
- f1과 accuracy는?
  - f1은 합리적인 평가이다.
- validation의 score와 test의 score의 일관성이 없으면?
  - 분리가 잘못된 분류라고한다.
  - split에 공을 들여야 한다.
  - testset은 좀더 어려운 데이터로 모아둔다고한다.
  - 라벨별로 비율을 잘 맞춰야 한다.
- 문제제기, 기존의 문제점, 해결방법, 미래지향적 목표
- 회사
  - 보이저엑스

## 후기
- 이번주는 저번 competition에 비해 좋았다
- 좀더 문제를 제기하고 접근하는게 부족하다.
- 토론게시판을 두려워했지만, 좀더 활용해볼 용기가 생겼다.
- k-fold가 성능하락해서 아쉬웠다
 
