---
layout: post
title: P-S3-DET_SEG-5
categories: AI boostP
tags: [ai,boost]
toc : true
math : true
---


## 강의확인
- baseline 소개
  - efficient unet
- 모델불러오기
  - segmentation models
  - `import segmentation_models_pytorch as smp`
- 이미지 출력 결과
  - (배치사이즈,클래스갯수,세로,가로)
  - 이미지가 2*2이고 클래스만큼 각 픽셀마다 채널이 존재
- 마스크 출력
  - (배치,세로,가로)
  - 클래스 축이 없고, 각 픽셀이 어떤 클래스 인델스를 가지는지 출력
- 시드고정 필수
  - 같은실험 같은결과를 내기위해
- 실험은 하나에 한조건으로
- valid의 중요
  - 제출횟수제한되어 제출전에 성능확인하는 방식
  - holdout
    - 20%는 고정
    - 20%가 학습에 참여 못함
  - k-fold
    - valid가 번갈아가면서 학습에 참여
  - stratified k-fold
    - class distriburtion을 고려
    - class분포를 유사하게 분리를한다.
  - group k - fold
    - 의료사진은 대부분 같은 클래스에는 같은 사람의 사진이 들어가게된다.
    - 이런 사진을 나눠서 valid로 한다고 하면, 이미 train에서 학습한 정보를 valid에서는 높은 점수를 받아서 학습 효율이 떨어진다.
    - train과 valid에 동일한 그룹이 나뉘지 않도록 그룹화 해주는거
- augmentation
  - 성능향상
  - 라이브러리 albumentation
  - 도메인에 맞게 적용하기
  - cutout
  - grid mask (cutout의 단점을 극복하기위해)
  - cut mix 두 이미지를 잘라서 붙이기
  - snap mix 두 이미지에 중요한 부분을 합치기
- 모델
  - HRnet등의 sota 확인
  - 기존 모델에서도 백본 변경, 다양한 모델의 환경을 확인
- learning scheduler
  - cosineAnnealingLR
  - reduceLROnPlateau
  - gradual warmup
- batch size
  - gradient accumulate
  - mixed precision training of deep neural network
    - 웨이트의 소수점을 32에서 16을 줄여서 배치사이즈 증가
- optimizer
  - adam, adamp,adamw
- 앙상블
  - k-fold
  - swa(stochastic weigh averaging)
    - weight를 업데이트가 아닌 평균낸다.
  - 시드앙상블
    - 시드만 바꿔서 앙상블

------

## 피어세션
- unet과 fpn을 사용
- loss는 여럭 결합하여 사용한다고한다.
- augmentation은 간단하게 사용한다고한다.
- unknown은 무엇인가?
- 많이 틀린 클래스찾기
  - 많이 틀린 클래스에 특화된 모델만들기
  - validation에서 한번 확인해보기?

------

## 오늘 한일
- 파이썬으로 변경
- efficient-b0 unet 확인

## 어떻게 했는지
- 노트북 형식을 파이썬으로 변경
  - 좀더 코드가 간결해졌다.
- smp(segmentation_models_pytorch)라이브러리를 이용하여 efficientnet unet을 사용


## 좋았던 점
- 파이썬으로 바꾸니 좀더 코드보는게 간결해졌다.


## 아쉬운 점
- 아직 smp로 모델을 불러서 여러번 확인해봐야 할거같다.
  - efficientnet b0는 성능이 낮았다.
- 파이썬 형식과 노트북에 randomseed를 고정해도 서로 다르게 바뀐다.
