---
layout: post
title: P-S3-수식인식-11
categories: AI boostP
tags: [ai,boost]
toc : true
math : true
---


## 오피스아워
- model interpretability
  - model 해석력
  - 모델이 어디를 보고 판단하는지를 알아야지~
- model agnostic interpretability method
  - 모델에 구애받지 않는 해석력
  - CBAM은 Attention에만 쓸수있다!
- lime(local interpretable model-agnostic explanations)
  - 고차원 전역적인 해석이 어려움
  - 지역적으로 작게 해석을 진행하는것
  - 이미지를 super-pixel로 변경해서 해석이 용이하게 한다.
  - f는 딥러닝모델, g는 linear regression
  - 순서
    - x로 x'을 만든다(seper pixel)
    - x'을 랜덤하게 suffle해서 z'을 구한다
    - f(z)를 계산
    - surrogate model - g를 학습한다고한다.
- SHAP
  - shapley(사람이름) additive explanation
    - 연봉측정하려고 만들었다고함
  - additive?
    - binary변수의 선형 결합으로 ㅇ루어진 explanation함수
    - 뭐지
  - method
    - 협업게임
      - lime관점
        - 팀게임 점수 = 개인점수+ 각영역의 선수의 점수
        - 불공평한 부분이 존재
        - 모든팀원 점수합은 전체 팀점수가 되어야한다(additive)
        - 랜덤이어서 그때마다 다름 (consistance)
    - 선수 중요도 f(with i ) - f(without i)
      - 게임 f, i는 선수
    - shapley value
      - 협업게임의 조건을 맞는 계산
- SHAP사용하기
  - [https://github.com/slundberg/shap](https://github.com/slundberg/shap)
- captum 써보기


## 해본것
- dim늘려서 진행중
  - hidden과 filter dim을 최대로 늘려서 진행
  - 베이스자체가 현재 v100의 메모리에 맞게 되어있어서 소폭 증가가됨
  - 진행중인데 뭔가 못건드리겟음


## 생각해본것
- beam search?
  - 어디다 적용해야할지?
- teacher forcing scheduler는?
  - 현재는 0.5로 고정됨
  - 스케줄러형식?


