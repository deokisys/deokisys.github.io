---
layout: post
title: 10.통계학과 시각화도구
categories: AI boost
tags: [ai,boost,pandas,matplotlib,seaborn,MLE,최대가능도]
toc : true
math: true
---

# 강의 복습 내용
- 시각화도구matplotlib와 seaborn의 사용법을 익힌다.
- 통계학관련 모수와 확률분포의 종류를 알고 가정한다.
- 이런 확률분포를 통해 데이토 모수를 추정하는 방식을 안다.
- 최대가능도 추정법MLE
  - 로그가능도로 많은 데이터를 계산하기쉽게 한다.

## 얻은 지식
- matplotlib
- seaborn
- MLE

----

## 시각화도구

### matplotlib
- 시각화하는 라이브러리
- 초창기 자주 사용된 도구
- 다양한 graph지원 pandas연동

- pyplot객체를 사용하여 데이터를 표시
- 객체에 그래프들을 쌓은 다음 flush한다.

```python
import matplotlib.pyplot as plt # 모듈 호출
X=range(100)
Y = [value**2 for value in X]


plt.plot(X,Y)#x축, y축

plt.show()#flush
```

  - plot을 할때 kewargs로 arg르 받아 고정된 argumnet가 없어 확인이 어렵다.

- matplotlib는 figure안에 axes로 구성
  - fiture위에 여러개의 axes를 생성
  - `figure`
    - 그래프를 그릴 하나의 큰 틀
  - `axes`
    - 하나의 그래프

```python
fig = plt.figure()# figure
fig.set_size_inches(10,5) # 크기
ax_1 = fig.add_subplot(1,2,1) #세로 1,가로2칸짜리에서 1번위치의 axes
ax_2 = fig.add_subplot(1,2,2)

ax_1.plot(X_1,Y_1,c="b")
ax_2.plot(X_2,Y_2,c="g")

plt.show()
```

- subplot 순서
  - 2,3일때

| 2,3,1 | 2,3,2 | 2,3,3 |
| :---: | :---: | :---: |
| 2,3,4 | 2,3,5 | 2,3,6 |


- set color
  - 색 지정
  - `plt.plot(x,y,color="#eeefff")`
  - `plt.plot(x,y,color="r")`
- set linestyle
  - 선 스타일 지정
  - `plt.plot(x,y,linestyle="dashed")`
  - `plt.plot(x,y,ls="dotted")`
- set title
  - plot위에 제목 표시
  - `plt.title("제목")`
- set legend
  - 범례표시, 범례의 스타일,위치 지정
  - `plt.plot(x,y,label = "line_1"` 해당 그래프에 이름 지정
  - `plt.legend(shadow=True,fancybox=True,loc="lower right")`
    - 그림자, fancybox, 위치는 우측 하단에 범례가 만들어진다.

- grid,xylim
  - 그래프의 보조선을 긋는 gird, xy축 범위 한계 지정
  - `plt.grid(True,lw=0.4,ls="--",c=".90")`
    - 보조선 생성, 선굴기, 모양, 색투명도를 지정한다.
  - `plt.style.use("ggplot")`
    - 초반에 스타일을 적용하면 알아서 그리드가 만들어진다.
  - `plt.xlim(-100,200`
    - x축을 -100,200까지로 그래프를 그린다.
  - `plt.ylim(-100,200)`
- 그래프 설명
  - `plt.text()`
    - 그래프에 글을 적을 수 있다.
  - `plt.annotate()`
    - 글도 적고, allowprops옵션을 통해 화살표를 그릴수 있다.

- 저장
  - `plt.savefig("이름",c="a")`
    - 그래프를 파일로 저장한다.

### matplotlib graph
- `scatter`
  - 점으로된 그래프
  - `plt.scatter(x,y,c="색",maker="마커 모양")`
  - s는 데이터의 크기를 지정하여, 데이터의 크기 비교가 가능하다.

- `bar chart`
  - 막대그래프
  - 많이 안쓰인다고 한다.
  - `plt.bar(x=위치,y=높이,color="색",width="굵기")`
  - `plt.xticks(x+0.5,("a","b","c","d"))`
    - 아래에 표시되는것 x+0.5간격으로 a,b,c,d라는 그래프 이름을 적어준다.
    - x축 변형
  - `plt.bar(bottom)`
    - bottom옵션은 막대그래프를 층으로 쌓는 형태이다.
  - `plt.barh()`
    - 세로축 기준으로 그래프 만들기
- `histogram`
  - 분포차트
  - `plt.hist(x,bins=100)`
    - x는 데이터들
    - bins가 가로축 갯수를 의미
- `boxplot`
  - 상자도표, 상자그림,상자수염 그림이라 하는 그래프
  - `plt.boxplot(data)` data는 (100,5)모양이면, 5개의 상자도표를 만든다.
  - 2차원의 데이터를 사용한다.
  - 최소, 최대, 중앙값(median)

## seaborn
- 세아봄
- 통계적인 기법을 시각화할때 사용
- matplotlib를 더 쉽게 지원해주는 도구
- 간단한코드+ 예쁜결과
- seaborn 튜툐리얼 따라하기

```python
import seaborn as sns# 기본 선언 및 호출

sns.set(style="darkgrid") # 스타일 지정

#기본제공 데이터 사용할 수 있다.
tips = sns.load_dataset("tips") 
fmri = sns.load_dataset("fmri")
```

### basic plots
- `lineplot`,`scatternplot`,`countplot`등 기본적인 plot
- `sns.lineplot(x="컬럼명",y="컬러명",data=fmri)`
  - x축카테고리이름, y축케테고리 이름, 데이터
  - 데이터와, 분포들을 그려준다.
- `sns.lineplot(x="컬럼명",y="컬럼명",hue="event"data=fmri)`
  - hue를통해 카테고리를 지정해준다.

- `sns.scatterplot(x="컬럼명",y="컬럼명",data=tips)`
  - x축이름, y축 이름, 데이터
  - 점 그래프
- `sns.regplot(x="컬럼명",y="컬럼명",data=tips)`
  - 선형회귀선을 넣어준다.
  - hue로 카테고리 지정 가능
- `sns.countplot(x="smoker",data=tips)`
  - 갯수를 세준다.
  - smoker라는 컬럼의 데이터들을 세준다.
  - hue로 카테고리 분리 가능
- `sns.barplot(x,y,data)`
  - 기본 평균을 보여준다.
  - 분포를 선으로 표시해준다.
  - estimater옵션으로 어떤계산을 할지 정할 수 있다. 기본 평균임

- `sns.distplot(tips["total_bill"],kde=False]`
  - kde옵션은 곡선유무
  - bins옵션은 데이터 갯수

### predefined plots
- `violinplot`
  - boxplot에 distribution을 함께 표현
  - 자주 사용한다고 한다.
  - 바이올린모양
- `stripplot`
  - scatter와 함계 category 정보를 표현
- `swarmplot`
  - 분포와 함께 scatter를 함꼐 포현
- `pointplot`
  - category별로 numeric의 평균 신뢰구간 표시
- `regplot`
  - scatter+선형함수를 함께 표시


### multiple plots
- 한개이상의 도표를 하나의 plot에 작성
- axes를 사용해서 grid를 나눈다.
- `replot`
  - numeric데이터 중심의 분포/선형 표시
- `catplot`
  - category데이터 중심의 표시
  - 이것도 자주 사용
  - kind옵션으로 swarm을 입력가능
- `FacetGrid`
  - 특정조건에 따른 다양한plot을 grid로
  - 결합분포를 볼때 사용한다.
  - 자주사용할것이다.
- `pariplot`
  - 데이터간의 상관관계표시
- `lmplot`
  - regression모델과 category데이터를 함꼐 표시


## 통계학 맛보기

### 모수

- 통계적 모델링
  - 적절한 가정위에서 확률분포를 추정하는것
  - 어떤 확률분포를 이용해 모델링 하냐가 중요한 선택이다.
- 유한한 개수의 데이터만으로 모집단의 분포를 정확하게 알아내긴 불가능
  - 근사적으로 확률분포를 추정
  - 모델을 예측하는 예측모형을 만드는 목적은 분포를 정확하게 맞추는 것보다 데이터와 추정방법의 불확실성을 고려해서 예측의 위험을 최소화
- `모수적(parametric)방법론`
  - 데이터가 특정 확률 분포를 따른다고 선험적(a priori) 가정한 후
  - 그 분포를 결정하는 모수(parameter)를 추정하는 방법
    - 정규분포라고 하면 "평균과 분산"을 모수라고 한다.
    - 이 평균과 분산을 추정하는 방법을 통해 데이터를 학습하는것
- `비모수(nonparametric)방법론`
  - 특정 확률분포를 가정하지 않고 데이터에 따라
  - 모델의 구조 및 모수의 개수가 유연하게 바뀌는 방법
    - 기계학습의 많은 방법론은 비모수 방법론에 속한다.
- 비모수 방법론이라고 모수가 없는게 아니다.
  - 모수가 무한히 많거나, 모수의 갯수가 데이터에 따라 바뀔때도 비모수

### 확률 분포 가정하기
- 확률 분포를 가정하는 방법은 히스토그램을 통해 모양을 관찰한다.
  - 베르누이분포
    - 데이터가 0또는1
  - 카테고리분포
    - 데이터가 n개의 이산적인 값
  - 베타분포
    - 데이터가 [0,1]사이에서 값
  - 감마분포,로그정규분포
    - 데이터가 0이상의 값
  - 정규분포, 라플라스분포
    - 데이터가 R전체에서 값을 가지는 경우
- 기계적으로 확률 분포를 가정해서는 안된다.
  - 데이터를 생성하는 원리를 먼저 고려해야 한다.
  - 검정을 해야한다.
  - 모수만 보기보단, 통계적 검정으로 적절하게 예측하고 있는지 확인해야한다.

### 모수 추정
- 정규분포를 예시
  - 모수는 평균, 분산이다.
  - 이 모수를 추정하는것이 통계량(statistic) 
    - 표본으로 부터 평균과 분산을 구한것이 표본평균과 표본분산
- `표집분포(sampling distribution)`
  - 통계량의 확률분포
    - sample distribution(표본분포)이랑 다르다고 한다.
  - 표본들의 분포가 아닌, 표본 평균과 표본분산의확률분포를 표집분포라고 한다.
  - 표본평균의 표집분포는 N이 커질수록(데이터를 많이 모을 수록) 정규분포를 따른다.
    - 중심극한정리(central limit theorem)
      - 모집단의 분포가 정규 분포를 따르지 않아도 성립
  - 주의
    - 표본들의 분포가 아닌 표본평균 표본분산의 확률분포를 표집분포
    - 표본평균의 표집분포(sampling distribution)은n이 커질수록 정규분포를 따른다.
    - 표집분포와 표본분포는 다르다.
    - 원래모집단의 분포가 정규분포를 따르지 않는다.
    - 표본분포(sample distribution)은 당연히 데이터를 많이 모아도 정규분포가 되지 않는다.
    - 통계량의 확률분포가 정규분포를 따른다.
    - 표본에서의 분포는 정규분포를 따르지 않을수 있다.

- 데이터가 늘어나면서 표본분산은 줄어들고 표본평균은 하나로 집중된다.
  - 원래 확률분포는 이항, 이항분표의 표본분포는 정규분포가 안됨
  - 하지만 이항분포에서 추출한 표본분포의 확률분포는 정규분포로 간다.
    - 이를 중심극한정리

### 최대가능도 추정법
- 표본평균이난 표본분산은 중요한 통계량
- 확률분포마다 사용하는 모수가 다르고 적절한 통계량이 달라진다.
- `최대가능도 추정법(maximun likehood estimation, MLE)`
  - 이론적으로 가장 가능성이 높은 모수를 추정하는 방법중 하나
- 가능도 함수
  - $$argmax L(\theta;x)$$라고 정의됨
  - 확률밀도,확률질량함수랑 같은데 관점이 다르다
  - 모수가 주어질때 x에 대한 함수로 해석을 하지만, 가능도 함수는 주어진 데이터 x에 대해 모수 세타를 변수로둔 함수로 해석
    - 확률로 해석하면 안된다.
  - $$argmax P(x | \theta)$$라 표현도 된다.
  - 데이터 x가 독립적으로 추출되었을때 로그가능도를 최적화
    - 곱으로 표현된다.
      - 로그함수는 곱을 더하기로 해준다.
    - 로그함수를 통해 곱셈으로 정의된 함수를 덧셈으로 바꿔준다.
      - 이유는?
- 로그가능도(log liked)
  - 데이터의 숫자가 수억단위가 되면 컴퓨터의 정확도로는 가능도를 계산하는것이 불가능
    - 곱셈이 너무 커지므로
    - 소수점이면 저무 작은숫자이므로 오차가 커진다고 한다.
    - 덧셈으로 바꿔주면 컴퓨터가 계산이 가능하고, 최적화도 가능하다.
  - 경사하강법으로 최적화하는데 미분을 사용한다는 의미
    - 로그라이크로 O(n^2)을 O(n)으로 선형적으로 변경하게 되어 빠르게 연산을 한다.
  - 대부분의 손실함수는 경사하강법이므로 , 음의 로그가능도를 최적화 하게 된다.

### 최대가능도 추정법 : 정규분포
- 정규분포
  - 확률분포 X로부터 독립적인 표본{x1,...xn}을 얻었을때
  - 최대가능도 추정법을 이용하여 모수를 추정하는 방법

- 모수는 평균과 분산이다.
- 세타 자리에 평균과 분산을 넣어준다.


- 로그가능도로 구한다.

- 로그를 계산하여 식을 전개

- 이제 미분을 해준다.
  - 각각 평균으로 미분, 분산으로 미분해준다.
  - 0이되는 평균과, 분산을 찾으면 가능도를 최대화하게 된다.


- 결과

  - 모수를 추정하는것과 유사하다.
  - 분산은 n-1나눴는데 n으로 나누고있다.
    - 약간 다르다.


### 최대가능도 추정법 : 카테고리 분포
- 이산확률변수에 해당하는 카테고리 분포
- mulinoulli(x;p1,...pd)
  - 베르누이라는 두개의 값중 하나를 선택하는 확률분포를 다차원으로 확장한 개념
- one-hot으로 표현된다.
  - 한개는1 나머지는 0
- 카테고리의 모수는 1차원부터 d차원까지 어떤값이 1또는 0이될 확률
  - 다 더해졌을때 1이되는 성질이 있다.

- 데이터 xi의 k번째 값을 승수로 취해주는 것으로 계산한다.
  - xi가 0이면 pk는 1, xi가 1이면 pk를 가지낟.

- 곱셈으로 되어있으므로 덧셈으로 바꾼다.
  - 모든 pk를 d까지 더하면 1이되야한다.

- nk는 주어진 x에 대해 k값이 1인 데이터의 갯수 

- 라그랑주 승수를 사용

- pk,람다로 미분
- 각각의 모수로 미분
  - 0이되어야한다.
- 우측은 제약식과 같음, 좌측은 nk/pk는 람다를 만족
  - 이를 조합하면 pk 는 nk/n1+..+nd가된다
  - 분모는 데이터 갯수 n과 같다.
  - pk는 nk/n와 같다
    - 각각의 차원에 해당하는 데이터의 카운트 숫자(경우수)를 세어서 비율을 구하는것이 모수


### 딥러닝에서 최대가능도 추정법
- 기계학습 모델에서도 사용가능
- 자중치 세타 = (W1 ,...,WL)라 표기했을때
  - 분류문제는 소프트맥스를 통해 조건부확률 벡터가 카테고리분포의 모수를 모델링한다.
- one-hot으로 표현한 정답레이블 y= (y1,..yk)을 관찰데이터로 이용
- 확률분포인 소프트맥스 벡터의 로그가능도를 최적화 할 수 있다.

- 수식 잘 외우기

- 확률 분포의 거리를 줄이기
  - 총변동 거리(TV)
  - 쿨백-라이블러발산(KL)
  - 바슈타인거리(wasserstein distance)

- 쿨백-라이블러 발산
  - 두개의 엔트로피로 분해한다.
  - 크로스엔트로피, 엔트로피
  - 정답레이블을 P, 모델 예측은 Q
  - 멀티레이어 퍼셉트론과 정답레이블에 대해 표현되는 손실함수
    - 분류문제에서 정답레이블을 p 모델예측을 q
    - 최대가능도수정법에서 사용되는 손실함수가사실은 쿨랙에서 첫번째 텀인 크로스엔트로피의 마이너스 텀과 같다(?)
    - 최대가능도에서 로그라이크드를 최대화시키는것과 정답레이블에 해당하는 p와모델예측 확률분포 q사이의 거리 쿨벨라이브러리 발산의 거리를 최소화와 같다.

- 손실함수가 어떻게 나왔는지 볼때, MLE관점에서 많은 유도가 되었다.







----

## 좀더 찾아보기
- 라이브러리
  - matplotlib
- matplotlib
  - figure,axes
- 그래프모양
  - scatter
  - 



- 모수

- 표본분포- 표본평균,표본분산을 통칭하는거


- 표집분포 
  - 여러개의 표본분포
  - 여러개의 표본평균과 표본분산을 통해 모평균 모분산을 예측하는것

- 표본평균
- 표본분산


- 중심극한정리
  - 왜 n/1를 쓰나



- 최대 가능도 추정법
- 로그가능도
- 쿨백라이블러




-----

## 피어세션 정리


- 표본분산은 모분산보다 작을 수 밖에 없다.
  - 링크1 블로그
  - 링크2 유튜브
- 수학적인 베이스가 매우 크다

- 왜 n-1을 나누나 - 자유도
  - 3개의 데이터가 있을때 123 평균은 2
  - 평균을 알고 있으면 12만 알고있어도 3이빠진걸 알 수 있다.
    - 3은 고정된다.
  - 이런게 자유도로 -1되도 된다는 의미로 된다.
- n-1을 나누는이유2 - 자유도
  - 1개의 데이터일때 무의미하기때문에 1개의 데이터를 뽑았을대의 경우를 지우기위해
- 자유도
  - 자유로운 변수

- 몬테카를로로 적분 구하기
  - 균등분포는?
    - 계산의 편의성
    - 2로 나눈거
  - iid

- further question
  - 3번 세타는 버터바른면이 떨어지는게 30프로, 뒤로떨어지느게 70프로일 확률
    - 베르누이 분포 공식이다.

- 간단 회고

## 의문

- 쿨백라이블러/최대가능도 추정법 같은이유?
  - 같은게 아니고, 같은 결과를 가진다.?
  - 쿨백은 거리를 계산
    - 이를 최소화 하면 정답에 가까워짐
  - 최대가능도는 
    - 쿨백의 거리를 최소화하는것을 이용하여 

----

## 마스터클래스 
- 임성빈교수님
- 책추천
  - 다이브 인투 딥러닝 책 추천
  - 패턴인식과 머신 러닝
- 수학과 코딩을 같이 공부하는 습관이 좋다.
- 수학적원리를 다 이해해야 하는지
  - 대부분 그때 공부를 하고 알고 진행하기도 한다고한다.
- 아무래도 수학적 기초는 필요하다.
  - 원리는 기본적으로 알아야 한다.
- 수식은 논문을 이해할때
- 이번주 수업은 기초중에 기초이다.
  - 복습을 하면서 익숙해지자.
- 부캠 수강생일때 
  - 코드랑 수학을 매칭해서 공부하기
- 수학전문가이기보다, 공부할 수 있는 추천
- 공부하는 방식을 키워드를 구글링 해서 직접 공부하기
  - 그걸로 예시들을 공부하기
  - 하나의 주제로 공부를 진행하기
- 대학원관련
  - 필수는 아니지만, 도움은 많이 된다.



----

## 주간 회고
- 수식이 많이 나왔다.
- 많은 수식을 외우기도 이해하기도 많이 어려운 주간이었다.
- 수학의 통계가 기초가 많이 부족했다 느꼈다.
- 완전히 내것이 되었다는 느낌이 안들었다.
- 다음 수업부터는 해당 수업에 대한 어느정도 기본지식을 쌓고 진행햐야 할거같다.
- 이번주의 내용을 어느정도 정리해서 마무리를 해야 할거같다.




