---
layout: post
title: 13.CNN의 기능과 구조
categories: AI boost
tags: [ai,boost,CNN,fully convolutional layer, alexnet, vggnet,googlenet, resnet, densenet,deconv,rcnn,fast rcnn, faster rcnn, sppnet, yolo]
toc : true
---


# 강의 복습 내용
- cnn의 구조와 사용되는 분야를 정리한다.
- cnn의 발전되는 방향과 구조를 정리한다.
- detection하는 여러 어플리케이션을 정리한다.


## 얻은 지식
- cnn의 역사
- cnn의 구조와 발전되는 방향
- 대표적인 cnn의 특징
- segemntation을 하는 네트워크의 특징
- 여러 detection 하는 네트워크

-----

## CNN
- convolution layer
- pooling layer
- fully connected layer

### convolution
- convolution은 두개의 함수를 섞는다는 의미
- 이미지,필터를 섞어 새로운 이미지를 출력한다.

### rgb image의 convolution
- 3차원 tensor로 rgb값만큼 3채널을 사용한다.
  - 필터는 (5,5,3)
  - 이미지는 (32,32,3)
  - 출력(feature)은 (28,28,1)이 된다.
- 여러개의 feature를 만들기위해서는 여러개의 필터를 사용한다.
  - 필터(5,5,3)가 4개일때
  - 이미지(32,32,3)이면
  - feature는 (28,28,4)를 출력한다.
- stack of convolution
  - 여러개의 convolution을 쌓아서 사용한다.
    - 계산하는법을 알아야한다.
  - `convolution layer`
    - convoluion과 활성함수가 하나의 세트

------


## convolution neural networks
- 구성
  - convolution layer
  - pooling layer   
    - convolution과 pooling은 feature을 추출
  - fully connected layer
    - 분류, 회귀
    - 파라메터의 값이 많이 사용한다.
    - 발전되는 성향은 fc를 많이 줄이는게 성능이라 한다.
- 구조를 보았을대 파라메터의 숫자를 파악하는 감을 잡는게 중요

### stride
- filter(kernel)을 이동하는 간격

### padding
- filter를 거치면 출력값이 적어진다.
- 입력과 출격의 크기를 유지하도록 입력이미지에 픽셀을 추가하는것


### parameter 계산
- padding(1) stride(1) 3,3 kernel
- (40,50,128)이미지에서 (40,50,64)로 feature를 추출했다면?
  - kernel은 (3,3,128)이 되고 64개가 사용되었다.
  - 3\*3\*128\*64 = 73728개의 파라메터를 계산할 수 있다.
- (13,13,128)->2048 fully connected일때
  - 13*13*128 * 2048 = 44,302,336이된다.
- convolution보다 fully connected가 파리메터가 많이 사용된다.
  - convolution으 필터에대해 모든영역에 계산되는게 아닌 일부를 계산하고 합치는 구조
  - fully connected는 하나의값에 모든 가중치들을 계산해서 진행한


### 1X1 convolution
- 이미지에서 영역을 보지 않는다.
- (256,256,128) -> (1,1,128,32) -> (256,256,32)
- 채널만 줄어든다.
  - dimension reduction
- 파라메터를 줄이고, 깊게쌓는다.    
  - 채널을 줄여서 파라메터를 줄여서 더 layer를 쌓을 수 있다.
- 차원을 조절할때 사용
- 예
  - bottoleneck architecture

-------

## mordern Convolutional Neural Networks
- 기껏해야 2018년도 기술
- 각네트워크의 파라메터숫자, depth를 보기
  - 파라메터는 낮아지고, depth는 늘어난다고한다.
- ILSVRC
  - 대회
  - ImageNet Large-Scale Visual Recognition Challenge
  - 분류,탐지,localization,segmentation

### AlexNet(2012)
- gpu의 성능이 낮았기 때문에 두개의 gpu를 사용하였다.
- 초반에 큰 (11,11)커널을 사용하였다.
- 구성
  - 5개의 convolutional layer, 3개의 dense layers(fully connected)
- 키 아이디어
  - ReLU를 활성함수로 사용
  - 2개의 GPU
  - LRL(local response normalization)
    - 입력공간에서 몇개의 response를 죽이는것
    - 많이 활용 안한다고 한다.
  - overlapping pooling
  - data augmentation
  - dropdout

#### ReLU
- overcome the vanishing gradient problem
  - sigmoid에 비해 너무 큰값에 대해서도 사용이 가능하다.

### VGGNet(2015)
- 19layer
- (3,3)convolution filter를 사용하였다.
  - (3,3)을 두번을 사용하는것과 (5,5)를 한번 사용하는것은 receptive field에 대해서는 같다.
  - 파라메터갯수를 줄일 수 있다.
- receptive field는 하나의 필터가 보는 영역의 크기라고 생각하면 된다.

### GoogleLeNet(2014)
- 22layer
- (1x1)convolution을 잘활용해서 전체적인 파라메터를 줄임
- 비슷한 네트워크를 반복적으로 사용함
  - NIN(network in network)구조
- inception Block
  - 하나의 입력에 대해 여러개의 receptive field를 거쳐서 여러개의 결과를 합치는 효과
  - (1x1)conv를 중간마다 들어가있다.
    - 이로 인해 파라메터의 숫자가 줄어들었다.
    - 1x1 convolution can be seen as channel-wise dimension reduction
      - 채널방향으로 차원을 줄인다고한다.

#### inception Block 예
- 일반적인 (3,3,128)-(3,3)->(3,3,128)이면 3*3*128*128= 147456개의 파라메터를 사용
- (3,3,128)-(1,1)->(3,3,32)-(3,3)->(3,3,128)
  - 1*1*128 , 3*3*32*128로 두개의 값을 합치면 40960으로 파라메터를 줄일 수 있다.
- recept field도 같고 채널도 같다.


### ResNet(2015)
- 네트워크가 커짐에 따라 학습이 덜된다고 주장
  - 하지만 그렇지 않다고 깊게만들게 됨
- convolution을 통해 나온것을 입력과 더해주는 원리
- skip-connection

### denseNet
- 더하기 대신 concatenation을 한다.
  - 채널이 점점 커진다.
- 중간에 채널을 줄이는 방식
  - 1x1conv로 feature를 줄인다.
- 줄이고, 늘리고 하는 방식을 반복한다.


------

## computer vision application
- cnn을 이용한 분야

## sementic segmentaion
- 이미지로부터 픽셀마다 분류하는것
  - 이미지의 모든 픽셀에 라벨을 구별하여 배경, 물건 종류를 구별하는것
- 자율주행에 많이 활용됨

### fully convolutional network
- 일반적인 CNN에서 dense layer를 없에는것
  - dense layer를 cnn으로 대체
  - 출력은 같다.(파라메터는 일치하다.)
    - 20,20,1000이었다면 20,20,1000의 커널로 1,1,1000을 만드는것
  - convolutionalization이라고 불린다.
- 특징
  - input dimension, 스페셜 dimension에 의존적이다.
- trasforming fully connected layers into convolution layers enable a classifiacation net to output a heat map
- 단순 분류에서 heat map을 통해 segmantaion이 가능해짐


### deconv
- 완전 역은 아니지만 padding을 통해 입력과 출력의 갯수로는 동일하게 만들어준다.
- fc의 결과를 원본과 맞춰주기 위해 사용

## Detection
- 바운딩박스

### R-cnn
- 무엇이 있는 영역에 classification을 수행

### SPPNet
- R-cnn과 비슷하지만, 이미지에서 cnn을 한번만
  - 나온 cnn의 feature map을 활용하여 영역을 잘라서 사용

### fast R-Cnn
- SPPNet의 컨셉인 cnn을 전체이미지에대해 진행후 사용
- 뒤에서 roi를 사용

### faster R-Cnn
- 초반 이미지의 바운딩박스를 뽑는 것도 네트워크로 만들자
  - region proposal network
- k개의 anchor박스를 사용


### YOLO
- you only look one
- faster r-cnn보다 빠르다.
- 바운딩 박스를 뽑는과정이 없다.


----


## 좀더 찾아보기
- fully connected
  - special dimension
  - heat map

-----

## 피어세션 정리
- cnn의 bias는?
  - 출력 채널 만큼 더하는것
- googlenet은 7\*1과 1\*7로 나눠져있다고 한다.
- strid는 파라매터 계산에는 상관없다고 한다.
- convolution과 correlation?
  - convolution은 맨처음게 맨끝이랑 곱하듯이 180도 돌려서 계산
  - correlation은 우리가 아는 커널이 같은위치끼리 곱하여 더하는계산 차이
  - convolution과 correlation은 서로 반대로 계산을 한다
    - f\*g, g\*f


----

## 과제
- cnn
  - nn.Sequential()의 유용함
- dog
  - 새로운 파일을 다운하거나 하면, ssh를 새로 연결해야한다.
  - 순서
    - 파일 다운
    - 파일을 보기 쉽게 정리
    - 파일을 train,test로 분류, 폴더로 나누기