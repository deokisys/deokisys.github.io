---
layout: post
title: 15.Generative model
categories: AI boost
tags: [ai,boost,Generative model,GAN,variational auto-encoder,ELBO]
toc : true
math : true
---


# 강의 복습 내용
- generative model이 무엇인지
- generative model의 트렌트와 방법론
- variational auto-encoder가 generative인 이유

## 얻은 지식
- generative model의 정의
- GAN의 종류

-----

## Generative Model

```
what i can not create. i do not understand
  - richard feynman
```

- 생성 모델
- [참고](https:deepgenrativemodels.github.io)

### generative model이란
- 단순히 이미지를 만들어내는게 전부인게 아니다.
  - 좀더 큰 개념을 가지고 있다.
- 주어진 학습 데이터를 학습하여 학습 데이터의 분포를 따르는 유사한 데이터를 생성하는 모델
- 생성모델을 만든다.
- generation
  - 강아지와 유사한 이미지를 만들어 내는것
  - tractable
    - 학습 데이터의 분포를 직접적으로 구하는 방법
    - 계산이 가능하다는 의미
- density estimation
  - 이미지를 학습하여, 어떤 이미지가 입력되었을대 확률을 통해 강아지같은지 판단
  - anomaly detection
  - 분류와 같다. 
  - explicit모델이라고 한다.    
    - 학습데이터의 분포를 기반으로 생성
    - 확률을 계산가능
  - implicit
    - 학습데이터의 분포를 몰라도 생성
    - 확률이 계산이 안됨


- unsupervised representation learing
  - feature learning

### 기본 discrete distributions
- 이산 분포
- bernoulli distribution(베르누이) (동전던지기)
  - 0또는 1이면 된다.
  - 숫자는 1이면 충분하다.
- categorical distribution(카테고리) (주사위굴리기)
  - 6면의 주사위 문제
  - n개의 경우인경우 n-1파라메터가 필요 
  - 파라메터는 확률이라 생각
  - -1이 되는 이유는 마지막 확률은 전체 나온 확률을 1로 빼주면 따로 확률을 구하지 않아도 된다.
    - 그러므로 파라메터 갯수는 전체 state의 갯수보다 1만큰 적은 숫자라고 생각한다.

### RGB 예시
- RGB각각 독립적
  - 각256만큼의 경우가 존재
- 파라메터
  - 255x255x255만큼 필요
  - 256면체 주사위를 3번 돌렸다고 생각하면 될듯
  - (256-1)x(256-1)x(256-1)이 된다고 생각함
- 하나의 픽셀에 대해 파라메터가 너무 많이 필요하다.

### 흑백 mnist 예시
- 총 n개의 흑백 픽셀이 있다
  - 2 x 2 x 2 ... x 2= 2^n의 경우의 수가 있다.
- 파라메터는 
  - 모든 픽셀이 dependence하다고 한다면,
  - $$2^n - 1$$이 된다.

- 모든 픽셀이 독립적이라고 가정한다면?
  - $$ p(x_1,\cdots,x_n)=p(x_1)p(x_2)\cdots p(x_n)$$
  - 모든 경우의 수는 2^n
  - 파라메터는? n개면 된다.
    - 각 각의 픽셀마다 1개씩 있으면 되니까
  - 모든 n개가 독립적이라는 가정으로 가능
  - 하지만, 이미지는 어느정도 인접한 픽셀끼리는 비슷한데 이렇게 독립적으로 한다면 화이트노이즈수준이다.

### Conditional Independence (조건부 독립성)
- 모든 경우가 연관(dependent)되면 파라메터가 너무 많다.
- 그렇다고 독립적(independent)이면 파라메터가 적어지지만, 원하는 이미지가 잘 안나온다.
- 3개의 중요한 법칙(rule)이 존재
  - chain rule(연쇄법칙)
    - 어떤 가정도 없음
  - bayes' rule
  - conditional independence
    - 가정  z가 주어질때 x,y가 independent하다.
- chain rule과 conditional independece를 잘 섞어서 결과를 내면 된다고 한다.

### chain rule

$$ p(x_1,\cdots,x_n) $$

- $$ p(x_1) $$   픽셀이 한개
  - 픽셀이 한개이므로 0또는1로 1개의 파라메터가 있다.

- $$ p(x_2 \mid x_1) $$ 두개일경우
  - 2개의 파라메터
  - x_1이 0일때, x_1이 1일때 해서 총 2개라고 한다.

- $$ p(x_3 \mid x_1,x_2) $$ 3개일경우
  - 4개의 파라메터

- 결국 1+2+2^2+...2^(n-1)이 되어, 2^n-1개의 파라메터가 필요하다.
  - 독립적인것과 같이 나온다.

### markov assumption
$$ X_{i+1} \perp (X_1,\cdots,X_{i-1}) \mid X_i $$
- i+1는 1부터 i-1까지 독립이다.
  - i가주어졌을때
  - (다음 ㅗ 과거들 | 현재)
  - 직전상태만 독립이 아니다고 
- i+1번째 픽셀은 i에만 dependent하다는 가정
  - 9번째는 10번째만 dependent하고, 1부터 8번째는 independent하다
- 체인룰과 같이 식으로 표현하면
$$ p(x_1,\cdots,x_n) = p(x_1)p(x_2 \mid x_1)p(x_3 \mid x_2)\cdots p(x_n \mid x_{n-1})$$
- 파라매터는 2n-1개 가 필요하다.
  - 계산해보기
- markov 가정을 통해 파라메터를 줄였다.
- auto-regressive model이라고 부른다.

### auto-regressive model
- 28x28크기의 mnist의 흑백 이미지가 주어졌다고 가정
- 우리의 목적은 p(x)=p(x_1,...,x_784)를 학습하는것, x는 0,1로 되어있다
- p(x)를 표현은 어떻게 하나?
  - chain rule로 joint distribution을 얻는다.
  - $$p(x_{1:784})=p(x_1)p(x_2\mid x_1)p(x_3\mid x_{1:2})\cdots $$가 된다.
  - 이것을 autoregressive model이라 한다.
    - 하나의 정보가 이전 정보들에 dependent한것을 의미한다.
  - `an ordering`으로 순서가 중요하다.
    - 이미지에 순서라는게 명확하지 않다.
    - 지그제그, 수평적과같이 여러 경우가 있다.
- markov를통해 이전픽셀 하나만 dependent한것도 auto-regressive, 이전픽셀 모든것이 dependent한것도 auto-regressive이다.
  - 이런전반적인것을 auto-regressive라고 한다.
- 어떤식으로 conditional independence를 주는지에 따라서, 전체 모델의 structure가 달라진다.


### NADE
- neural autoregressive density estimator
- i번째 픽셀을 이전의 모든 픽셀에 dependent하게 한것
  - i번째 픽셀에 대해서는 1부터 i-1까지의 모든 픽셀을 입력값으로 받아서 확률을 얻는다.
- 입력 weight가 점점 늘어난다.
- `explicit` 모델이다.
  - generation만 하는게 아니다.
  - 임의의 784개의 입력이 주어지면(mnist이미지)
  - 입력의 확률을 계산이 가능하다.(구분이 가능하다.)


### pixel RNN
- pixel를 만드는 model
- rnn으로 generat하겠다는 차이점
- ordering 에 따라 이름이 다르다.
  - row LSTM
    - i번째 픽셀보다 위쪽의 정보를 활용
  - Diagonal BiLSTM
    - 이전까지의 픽셀 정보?
- 훼손된 이미지도 복원할때 사용가능 한것으로 보임
- [참고](http://ai-hub.kr/post/98/)


----------


## latent variable model
- variational inference and deep learnin: A new synthesis
  - D.kingma
  - 논문 추천
  - adam을 만드셨다.

- autoencoder
  - generative model인가?
  - variational autoencoder가 generatie model 이 되도록 하는게 무엇인지를 생각하자.
    - 어떤차이가 있고 variational autoencoder가 가지는 것

### variational auto-encoder
- Variational inference(VI)
  - 목적은 posterior distribution(사후확률)을 최적화 할수 있는 variational distribution을 찾아야한다.
  - posterior distribution
    - $$ P_\theta (z\mid x)$$
    - observation이 주어졌을때 목적이 되는것에대한 확률?
  - variational distribution
    - $$ q_\phi(z\mid x) $$ 
    - posterior distribution을 계산하는데 불가능 할때가 있다.
    - 최적화할수있는 값으로 근사하기 위한 분포
  - variational distribution와 posterior distribution사이를 최소화 하는 KL divergence(쿨백 라이블러발산)를 찾는다.

- [참고1](https://deepinsight.tistory.com/127)
- [참고2](https://medium.com/@kim_hjun/approximate-inference%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80-35653b963546)

![variational Auto Encoder](https://user-images.githubusercontent.com/24247768/107044866-36011600-6808-11eb-89eb-5352948cc165.png)
- 목적은 variational distirbution을 학습하는것(encoder)

### 어떻게 찾나?
- posterior distribution이 뭔지 알 수없는데 이를 근사하는 variational distribution으로 찾는다
  - 알지못하는 물체(obejct)와 근사하게 만드는것
- 이를 가능하게 해주는게 `ELBO`라고 한다.

### ELBO

![ELBO](https://user-images.githubusercontent.com/24247768/107045546-f8e95380-6808-11eb-9067-d8f33143ee64.png)
- 목적은 KL divergence를 통해 posterior distribution과 variational distribution을 줄이는것이다. 하지만 불가능
- tractale은 계산가능하다는 의미
- ELBO가 tractable로 계산 가능하므로, ELBO를 올린다.
  - ELBO를 계산하여 ELBO를 증가시킴으로서, 반대인 objectiv를 구한다는 컨샙 




- 목적
  - 입력 x에 대해 비슷한 그 입력을 잘 표현하는 latent space를 찾고 싶다.
    - z라는 latent spce를 찾으려 한다.
  - z라는 posterior distribution를 모른다.
  - 이를 찾기 위해variational distribution, encoder로 z를 근사 하고 싶다.
- ELBO를 늘리는것이 Posterior과 variational의 거리를 줄이는것과 같은 효과가 있다는 것을 유도
  - ELBO는 Reconstruction Term과 Prior Fitting term으로 구성된다.
    - reconstruction term은 x라는 입력을 encoder를 통해서 decoder로 돌아오는 reconstruction loss를 줄이는것
    - prior fitting term은 x라는 여러 입력을 통해 만들어진 latent space의 점들의 분포가 사전분포와 비슷하게 만들어지도록 (enforce)한다.
  - 이 때문에 variational auto-encoder가 genrative model이 되는것이다.
  - explicit모델이아닌 implicit모델이 된다.

- 예
  - 10만개일때 5만개로 여러번하면 10만개짜리랑 비슷할거다.


- 입력으로 부터 latent space로 보내고 나온 사전 분포에서 sampling을 한다.
- 이 sampling을 decoder를 통해 나온 이미지를 generation result라고 본다.
- 그냥 auto-encoder는 generative model 이 아니다.

### key limitation
- VA는 explicit모델이 아니다. intractable모델이다.
  - 입려이 주어질때, 얼마나 근사한지 알기 어렵다.
- the prior fitting term must be differentiable, hence it is hard to use diverse latent prior distributions
  - 해석 불가...
- isotropic gaussian을 사용한다고 한다.



## Adversasarial Auto-encode
- VA의 단점은 encoder를 활용할때 KL divergence를 활용한다는 것
  - gaussian이 아닌경우 활용이 안된다고 한다.
  - gaussian을 활용하지 않고싶으면?
- GAN을 활용하여 posterior과 variational을 맞춰준다.
  - prior fitting term을 GAN으로 대체한것


## GAN
- Generative Adversarial Network
- 아이디어
  - 도둑은 위조지폐를 생성
  - 경찰은 위조지폐를 분별
  - 도둑은 더 진짜같은 위조지폐를 만들도록
  - 경찰은 위조지폐를 더 잘 분별하도록

### VAE와 GAN
![VAE와GAN](https://user-images.githubusercontent.com/24247768/107061131-250dd000-681b-11eb-9b41-87c5e2c7d7a3.png)
- VAE
  - 입력 x를 encoder를 통해 z로 진행 
  - z를 decoder를 통해 x로 변환
    - 이러한 과정으로 학습
  - generation단계에서는 p(z)라는 샘플링을 통해 decoder를 통해서 나온 x가 generation결과가 된다.
- GAN
  - z라는 latent distributiton에서 출발하여 G 를 통해 Fake를 만든다.
  - D(discriminator는)는 Fake와 Real(정답)을 입력받아 True/False를 학습
  - G(generator)는 D입장에서 True가 나오도록 G를 업데이트
  - D는 결과로 나온 이미지들이 실제 이미지들과   

### GAN objective
- generator와 discriminator사이을 서로 싸우는 게임
  - 한쪽은 높게, 한쪽은 낮게
- discriminator
  - 최대로 만들기
  - $$ D^*_G(x) = \frac{p_{data}(x)}{P_{data}(x)+p_G(x)}$$
  - generator가 고정 되어있을대 이를 항상 최적의 분별하는 optimal discriminator는
  - 이게 높으면 True, 낮으면 False로 나오도록 하는것
- generator
  - optimal discriminator를 적용한다면
  - JSD(jenson-shannon divergence)가 나온다.
  - $$ V(G,D^*_G(x)) = 2D_{JSD}\left[ p_{data},P_G\right] - log4$$
  - gan의 objective는
    - 데이터를 만드는 distribution과 generator의 distribution사이를 KL로 최저화 하는것


### 종류
- DCGAN
  - dense를 활용
- info-GAN
  - g을 통해 이미지를 만들기만 하는게 아닌, c라는 클래스를 랜덤하게 입력으로 주어준다.
  - c라는 특정 모드에 집중하게 해준다고 한다.
- text2image
  - 문장으로 부터 이미지를 만든다.
- puzzle-gan
  - 교수님 참여작
  - 이미지의 일부들 gan으로원본 이미지를 만든다.
- CycleGAN
  - 이미지 사이에 도메인을 바꾸는것
    - 말을 얼룩말로, 여름을 겨울이미지로 바꾸는 예시
  - cycle-consistency loss라는 중요한게 있다.
  - 학습을 위해서는 동일한 이미지에 다른 도메인이 있는 이미지가 필요하다.
    - cycleGAN은 이런 데이터가 필요없이 가능하다고 한다.
  - 두개의 GAN이 존재한다한다.
- Star-GAN
  - 이미지를 특정 도메인으로 변경이 가능하도록 해준다.
    - 조절이 가능
  - 머리색변경, 성별전환 이미지를 만들어준다.
- Progressive-GAN
  - 처음부터 고차원이미지로 학습하면 힘드니까
    - 저차원부터 학습을 진행하고 점차 이미지를 키워가면서 학습을 진행하는 컨셉



----


## 좀더 찾아보기
- explicit
- implicit

- ㅗ모양은 독립

- NADE
- pixel RNN
  - row LSTM
  - Diagonal BiLSTM
- posterior distribution
- KL divergence
- latent space?(잠재공간)
  - 딥러닝의 latent space란 데이터를 통해 추출한 feature들의 분포 공간이라 한다. 
  - [참고1](https://towardsdatascience.com/understanding-latent-space-in-machine-learning-de5a7c687d8d?gi=f46434b577e1)
  - [참고2](https://dev-hani.tistory.com/entry/Latent-space-%EA%B0%84%EB%8B%A8-%EC%A0%95%EB%A6%AC)

- discriminator
  - 판별기

-----

## 피어세션 정리
- 다들 어렵다.
- markove assumption
- RGB
  - 256x256x256이 255x255x255가 된 이유는?
  - 각 주사위(256면채)를 3번던졌다고 생각? 맞는지?
- 파라메터란?

- generation
  - 비슷한걸 만든다는 기본
  - 비슷한걸 만들려면 비슷한것을 찾아야 하니까 

- 사후확률 분포
  - 



-----

## 마스터 클래스
- 최성준 교수님
- 실무
  - pytorch도 많이 쓰고, tf도 많이 쓴다고 한다.
- 연구와 실무
  - 연구는 밑바닥부터 구현은 해야한다.
  - 실무는 가독성이 중요하다.
- 논문 팁
  - 실험위주로 보신다.
  - 서론을 열심히 보자
- 파라메터와 성능
  - 파라메터를 줄이면 성능이 오른다는데 파라메터를 늘리니까 성능이 올라갔다.
  - 성능의 정의에 따라 다를듯
- 트렌드 잡는 팁
  - 논문 많이 읽는 사람을 잡아라...
- 조교 김재열님이 파이토치 고수다.
  - 무식하게 따라 치는것도 연습법
- 코드의 차원관련 연습
  - 레이어의 파라메터를 계산하는 연습을 해보자
  - 네트워크의 크기가 그려진다.

----

## 후기
- 이번주는 ai의 기초와 다양한 종류를 알 수 있었다.
- 전체적인 컨셉을 알수 있었고, pytorch가 처음으로 진행한 강의였다.
- 하지만 pytorch의 기초도 부족하고, 구현하는 연습이 많이 부족하다 느꼈다.
- 전체적으로 세세하게 알기보단, 어떤 컨셉과 아이디어를 적용했는지를 중점적으로 학습하였다.
- 좀더 pytorch를 이용한 간단한 과제를 조금씩이라도 진행해야 한다고 생각했다.
