---
layout: post
title: 30.이미지 분류와 annotation data의 효율적 학습
categories: AI boost
tags: [ai,boost,CNN,augmentation,RandAugment,transfer learning,knowledge distillation,pseudo-label,semi-supervised,self training]
toc : true
math : true
---


# 강의 복습 내용
- image classification
  - 이미지 분류
- annotation data efficient learning
  - 데이터 변형
    - augmentation
  - pre-trained information
    - 사전에 미리 학습한것을 사용하여 효율적으로 학습
    - transfer learning
      - convolution으로 feature를 따로 학습한것을 활용
    - knowledge distillation
      - 선생이되는 모델을 이용해 다른 모델을 학습
  - 라벨이 안된 데이터 학습
    - semi-supervised
    - self training


## 얻은 지식

-----

## image classification
- 이미지 분류
- k Nearest Neighbors(K-NN)분류
  - 근처의 k개의 이웃들을 통해 자신이 어떤분류인지 판단하는것
- 모든 이미지 분류하는데 오래걸린다.
  - 메모리 용량, 시간
- 이를 해결하기위해 압축하여 특징을 추출하는 neural network를 이용한다.
  - CNN

### CNN 
- single fully connected layer networks
- locally connected neurlal networks
- 다양한 CV에서 backbone으로 사용된다.
  - image-level classification
    - 분류
  - classification+regression
    - 분류 및 영역검출
  - pixel-level classification
    - 픽셀단위 분류

### CNN구조의 이미지 분류 역사
- AlexNet
  - LeNet-5를 기반
- VGGNet
  - fine tunning

## Annotation data efficient learning
- 거대용량의 데이터를 가지는게 어렵다.
  - 이러한 대용량데이터를 효율적으로 학습하는 방법이 필요
- data augmentation
- leveraging pre-trained information
- leveraging unlabeled dataset for training

### data augmentation
- data들은 편향(bias)되어있다.
  - 특정구도로 보기좋은 방식으로 이미지를 얻었기때문이다.
  - training data는 카메라로 찍은것으로 real data와는 다르다.
  - 밝은 이미지, 어두운 이미지의 차이를 못알아 볼수있다.
- data를 일부 변화를 해준다.
  - 자르기, 밝기, 변형, 회전 등
  - NumPy에 다양한 methods가 존재
- 최고의 augmentation을 찾기
  - random하게 augmentaion을 적용하여 성능이 좋은것을 탐색
    - RandAugment
  - 어떤 aumentation을 할지 , 어느정도로 적용할지 

### leveraging pre-trained information

#### transfer learning
- 데이터수가 많이필요하고 lable도 필요하다.
  - 단기간에 어렵다
  - 사람이 하는일이라 원하는 결과를 못얻을 수 있다.
- 기존에 학습한 사전지식을 활용하여 연관된 새로운 task를 얻는것
  - 데이터 셋으로 학습하여 또다른 데이터셋에서 활용
  - 한 데이터셋에서 다른데이터셋에서 사용될 공통된 지식이 있다.
- 방법1
  - ![그림](https://user-images.githubusercontent.com/24247768/110328435-b365b380-805e-11eb-82aa-9e682f5d2ec8.png)
    - 10개의 dimenstion을 출력하는 사전에 학습하고
    - convolution은 고정, fully connected layer를 교체하여 100개의dimension을 출력하는 새로운 모델을 학습한다.
- 방법2
  - ![그림](https://user-images.githubusercontent.com/24247768/110328594-e1e38e80-805e-11eb-96be-de8046f0b031.png)
    - 미리 학습하는것은 같고, convolution은 가중치를 낮게, fully connected는 가중치를 높게 learning late를 준다.

#### knowledge distillation
- 큰모델(선생)을 작은모델(학생)로 지식을 전달
- 모델을 압축
- unlabeled dataset를 위해 psudo lable(soft label)을 만들때 사용한다. 
- ![그림](https://user-images.githubusercontent.com/24247768/110328987-5f0f0380-805f-11eb-8876-92dd47a3abfb.png)
  - KL은 선생과 학생의 결과를 비슷하게 역전파를 학생에게만 전달
  - distillation loss는 선생모델과 유사한 결과에 대한 loss
  - student loss는 실제 ground truth와의 loss
  - distillation loss는 soft prediction, student loss는 hard prediction을 적용
    - 아무래도 선생이 가르치는것은 약간의 만들어진 라벨과 같아서 학습할때 완벽히 정답이라는것을 보장이 안되므로
    - student loss로 올바른 정답(right answer)을 학습, distillation loss로 선생모델의 지식을 학습
- [참고](https://light-tree.tistory.com/196?category=755497)

### leveraging unlabeled dataset for training

#### semi-supervised learning
- 전체데이터셋에서 label된 데이타셋은 일부에 불과하다.
- unlabeled 데이터를 목적성있게 잘 사용하는것
- semi-supervised learning은 label된 데이타와 label이 안된 데이터을 활용하여 학습
- ![그림](https://user-images.githubusercontent.com/24247768/110329069-7cdc6880-805f-11eb-800f-704ed82322e5.png)
  - label 데이터를 학습
  - 학습된 모델을 이용해 unlabel 데이타를 pseudo-labeled 데이터를 얻는다.
  - pseudo-labeled데이터와 label데이터 두가지를 이용해 다시 학습을 진행한다.

#### self training
- augmentaion+ teature,student network + semi-supervised learning
  - 다 결합한것
- ![그림](https://user-images.githubusercontent.com/24247768/110329297-bd3be680-805f-11eb-8ec5-8010097f65be.png)
  - teacher model을 학습하여 unlabeld를 pseudo-labeld로 예측한다.
  - labeld와 pseudo-labeled 두 데이터셋으로 student model을 학습
    - 이때 RandAugment를 통해 데이터를 늘린다.
  - 이후 teacher자리에 student로 교체한다.
    - 이를 반복
  - student model은 점점 커진다고 한다.


## 출처
- Yun et al.,CutMix:Regularization Strategy to Train Strong Classifiers with Localizable Features,ICCV2019
- Cubuk et al.,Randaugment:Practical automated data augmentation with a reduced search space,CVPRW2020
- Ahmed et al.,Fusion oflocal andglobal features for effective image extraction,AppliedIntelligence2017
- Oquab et al.,LearningandTransferringMid-LevelImageRepresentationsusingConvolutionalNeuralNetworks,CVPR2015
- Hinton et al.,Distilling the Knowledge in a Neural Network,NIPSdeep learning workshop2015
- Li &Hoiem,Learning without Forgetting,TPAMI2018
- Lee,Pseudo-label:ThesimpleandEfficientSemi-SupervisedLearningMethodforDeepNeuralNetworks,ICMLWorkshop2013
- Xie et al.,Self-training with Noisy Student improves ImageNet classification,CVPR2020

----

## 좀더 찾아보기
- k-nn
- LRN
  - Batch Normalization

-----


## 피어세션 정리
- size와 shape의 차이
  - numpy는 flat해서 나온다.
  - torch는 동일
    - size(), shape이다.
    - size를 연결해주는 것인듯
- pytorch hook이 존재
  - Model안에 존재
- 6시반 과제해설
  - 3시부터 5시15분
### 과제
- accuracy
  - mlp를 참고하심




