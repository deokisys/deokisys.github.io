---
layout: post
title: 31.이미지분류2와 FCN
categories: AI boost
tags: [ai,boost,GoogLeNet,inception module,auxiliary classifier,ResNet,Residual block,skip connection, Semantic segmentation,
fully convolutional network,FCN,upsample,
Transposed convolution,U-Net, DeepLab, Conditional Random Fields,CRF,Dilated convolution,depthwise separable convolution,Deeplab v3+,receptive field]
toc : true
math : true
---


# 강의 복습 내용
- image classification2
  - GoogLeNet
    - inception module
    - auxiliary classifier
  - ResNet  
    - Residual block
    - shortcut connection
    - skip connection
- Semantic segmentation
  - FCN(fully convolutional network)
    - fully connection, fully convolution
    - upsample
    - Transposed convolution
  - U-Net
  - DeepLab
    - CRF(Conditional Random Fields)
    - Dilated convolution
    - depthwise separable convolution
    - Deeplab v3+



## 얻은 지식

-----

## image classification2
- 깊은 layer의 문제
  - gradient vanishing/exploding발생
  - 계산복잡도 증가
    - 메모리 증가

### GoogLeNet
- 수평적으로 확장
- 한층에 여러 필터를 적용
  - 그만큼 계산이 커진다.
  - 이를 위해 1x1 convolution을 사용하여 채널을 줄인다.
    - inception module
- auxiliary classifier
  - gradient vanishing을 해결하기위해 중간마다 존재
  - 아래 계층에게 gradient를 주입해준다.
  - 학습에서만 사용, 테스트에서는 사용이 안된다.

### ResNet
- layer를 깊게 쌓아서 좋은 성능을 보여줬다.
- layer를 쌓으면 overfitting이 될거같다는 의견이 있었다.
  - overfitting은 일어나지 않았고 어느시점부터 성능이 유지되는것을 확인
  - 이를 통해 최적화가 문제라고 판단
- Residual block을 사용
  - 자기자신을 보존
  - 더해서 사용
  - shortcut connection(skip)으로 층이 쌓이면서 생기는 vanishing gradient를 해결하려함
  - 학습시 역전파를 통해 gradient를 지나가는데, shorcut을 지나가거나 안지나가고 layer를 지나가는 경우를 블럭마다 고려한다.
    - 이로인해 residual module의 갯수인 n이 있으면 2의 n승만큼의 경로를 가지게 되서 복잡한 매핑을 학습이 가능해진다고 한다.

### ResNet이후
- DenseNet
  - 이전의 모든 입력들도 사용
  - concat을 사용
- SENet
  - attention
- EfficientNet
  - deep, wide,high resolution을 조율해서 효율적인 비율 찾기
- Deformable convolution
  - 사람이나 동물은 형태가 부분적으로 변화되므로 제안
    - 팔,다리
  - 단순한 정사각형이 아닌 비정형화된 형태로 feature를 뽑게된다.

### 요약
- AlexNet
  - 간단한 CNN구조
  - 고용량, 낮은 정확도
- VGGNet  
  - 간단한 3x3 convolution
  - 고용량, 복잡한 계산
- GoogLeNet
  - inception module과 auxiliary classifier를 가짐
- ResNet
  - 깊은 layer와 residual block
  - 적당한 효율성을 가진다.

#### backbone으로 무엇을쓸까
- GoogLeNet이 어느정도 괜찮은 성능을 가진다.
  - inception module과 auxiliary classifie를 가지기 때문에 사용하기 복잡하다.
- 일반적으로는 VGGNet과 ResNet을 사용한다.
  - 간단한 3x3 conv layer로 구성되어있다.


## Semantic segmentation
- 각 픽셀을 카테고리로 분류하는 task
- ![그림](https://user-images.githubusercontent.com/24247768/110470570-5c271800-811e-11eb-8805-79c7b5e51dca.png)
  - 각 픽셀단위로 카테고리를 분류하여 색이 다르게 보이는것을 볼 수 있다.
- 영상의 컨텐츠를 분석할때 사용
  - 의료, 자율주행 등
  - computational photography
    - 영상편집으로 일부를 제외하고 합성하고 자르는데에도 사용

### Fully Convolutional Networks(FCN)
- ![그림](https://user-images.githubusercontent.com/24247768/110470675-7b25aa00-811e-11eb-9df1-8023929d59b6.png)
- end-to-end semantic segmentation
  - end-to-end는 입력부터 출력까지 전부 미분가능한 신경망 형식을 말한다.
- 입력과 출력이 같은 해상도로 나온다.
  - 기존 AlexNet은 입력해상도가 달라지면 flatten할때 fc layer와 호환이 안되는 문제가 있다.

#### Fully connected와 Fully convolutional의 차이
- Fully connected
  - 공간정보를 고려하지 않고, 고정된 차원의 벡터를 출력
  - ![그림](https://user-images.githubusercontent.com/24247768/110471932-15d2b880-8120-11eb-8914-3ce1497d86ab.png)
    - 한차원들을 모두 모아서 flattening을 적용
    - 이를 fully-connnected를 한다.

- Fully convolutional
  - 출력이 벡터 형식이 아니고 spatial coordinate를 유지한다.
  - ![그림](https://user-images.githubusercontent.com/24247768/110472027-33a01d80-8120-11eb-911f-415e126cb316.png)
    - 1x1 convolution을 적용
    - spatial한 정보가 유지되는것을 볼 수 있다.

#### Fully convolution의 한계
- 한계점은 예측한 결과가 입력에 비해 낮은 resolution을 가지게된다.
  - 큰 receptive field, pooling layer로 인해
  - 이를 위해 upsampling이 필요하다.

#### upsampling
- 작은 activation map을 입력 resolution으로 확장
  - transposed covolution
  - upsample and convolution

#### Transposed convolution
- ![그림](https://user-images.githubusercontent.com/24247768/110472145-58949080-8120-11eb-8b52-aed94c476920.png)
  - convolution의 순서를 바꾸는 방식으로 진행한다.
- 커널 크기과, stride를 잘 조정해야한다.
  - 중복이 되는 부분이 있어서 체크문양이 나타난다.
  - ![그림](https://user-images.githubusercontent.com/24247768/110472205-6ea25100-8120-11eb-9d19-917cef8c0f47.png)

#### upsample과 convolution을 같이 사용
- transposed의 중첩문제를 해결하기위해 사용
  - transposed는 한방에 처리한다.
- upsampling으로 interpolation(nearest-neighbor,Bilinear)를 convolution으로 적용
  - 그냥 늘리기보단, 
  - ![그림](https://user-images.githubusercontent.com/24247768/110472309-8e397980-8120-11eb-9666-f73af6ec4d4e.png)

#### skip connection
- score map을 확장하기 위해 skip connection 추가
- ![그림](https://user-images.githubusercontent.com/24247768/110472868-3f401400-8121-11eb-8c63-9338467933d1.png)
  - FCN의 레이어를 보면 점차 로컬의 영역을 보지만, 깊어질수록 넓은 영역을 보는 성질을 가진다.
- ![그림](https://user-images.githubusercontent.com/24247768/110473916-6a773300-8122-11eb-8f98-1180c27b1283.png)
  - 중간 과정에서 upsampling을 한것을 같이 사용하는 방식
  - FCN-32s는 마지막것만, FCN-16s은 중간에 pool4도 같이, FCN-8s은 pool3도 같이
  - ![그림](https://user-images.githubusercontent.com/24247768/110473983-7c58d600-8122-11eb-9dfb-a8f2400f9fe5.png)
    - 중간단계를 같이 쓰는 FCN-8s로 갈수록 좀더 최적화되어 표시되는것을 볼 수 있다.


### Hypercolumns for object segmentation
- ![그림](https://user-images.githubusercontent.com/24247768/110474150-ad390b00-8122-11eb-8985-8904ff239cd7.png)
- 낮은 레이어와 높은 레이어의 특징의 해상도를 맞춰서 사용
  - Hypercolumns이 존재
- FCN과 유사하지만, end-to-end가 아니다.
  - bounding box부분을 따로 사용

### U-Net
- fully convolutional networks
- 낮은층과 높은층의 특징을 잘 결합하는 방식을 제안
- ![그림](https://user-images.githubusercontent.com/24247768/110474631-40724080-8123-11eb-836a-74cc953495f7.png)
  - u모양
  - contract path 
    - convolution적용, pooling을 통해 해상도를 낮추고, 채널을 증가
    - feature map은 절반씩 감소, channel은 두배씩 증가
  - expanding path
    - upsampling 과정으로 단계적으로 해상도를 증가
    - feature map은 두배씩 증가, channel은 절반씩 감소
    - 같은 층의 레이어와 concatenating하여 적용한다.
      - local한 정보의 feature map을 제공하여 concatenation한다.
  - spatial size가 홀수이면?
    - 7x7->3x3, 3x3->6x6으로 해상도 차이가 발생한다.
    - 홀수가 발생하지 않도록 주의해야 한다.

### DeepLab

#### Conditional Random Fields(CRF)
- 후처리로 사용되는 툴
- 픽셀과 픽셀 사이의 관계를 이어준다.
  - 픽셀맵을 그래프로 보는것
- ![그림](https://user-images.githubusercontent.com/24247768/110474706-56800100-8123-11eb-82cc-1bcce7043a17.png)
  - DCNN을 보면 전체적으로 뿌옇게 결과가 나온다.
  - CRF를 통해 실제 이미지의 경계를 이용하여 뿌옇게 나온 score map이 들어맞도록 확산해준다.
    - 반대로 배경도 확산을 통해 이미지 경계까지로 확산을 진행
    - 둘의 경계의 차이를 명확하게 해준다.

#### Dilated convolution
- convolution 커널 사이에 빈 공간을 넣는것
- ![그림](https://user-images.githubusercontent.com/24247768/110474766-6861a400-8123-11eb-895d-a82834ebbad0.png)
  - 좌측은 일반적인형태이지만, 우측은 1칸씩 띄어져 있는것을 볼 수 있다.
  - 좀더 넓은 영역을 볼수있다.
  - 파라메터 수는 늘어나지 않는다.
  - 이를통해 receptive field가 커진것을 볼 수 있다.

#### depthwise separable convolution
- semantic segmentation입력 해상도가 크기때문에 연산을 줄이기 위해 사용
- ![그림](https://user-images.githubusercontent.com/24247768/110474839-7dd6ce00-8123-11eb-8801-bcb161e42065.png)
  - 좌측은 기존의 convolution과정으로 한번에 커널크기만큼 전체 채널을 한번에 계산한다.
  - 우측은 채널별로 convolution을 진행, 채널축으로 convolution을 진행
  - 좀더 효율적으로 계산이된다

#### Deeplab v3+
![그림](https://user-images.githubusercontent.com/24247768/110474894-8e874400-8123-11eb-89a2-f01bd61721c8.png)



----

## 좀더 찾아보기
- deeplab v3+

-----


## 피어세션 정리
- 이번주 목요일 성익님 못오심
- receptive field
  - receptive 영역은 (p-1)*s + k
    - p는 poolinglayer
    - s는 stride
    - k는 커널
  - [참고1](https://medium.com/mlreview/a-guide-to-receptive-field-arithmetic-for-convolutional-neural-networks-e0f514068807)
  - [참고2](https://theaisummer.com/receptive-field/)





