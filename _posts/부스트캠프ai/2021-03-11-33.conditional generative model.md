---
layout: post
title: 33.conditional generative model
categories: AI boost
tags: [ai,boost,instance segmentation,mask r-cnn,yolact,yolactedge,panoptic segmentation,upsnet,vpsnet,landmark localization,hourglass network,dence pose,RetinaFace,detecting objects as keypoints,cornernet, centernet, conditional ,
GAN, super resolution, pix2pix, cycleGAN, cycle- consistency loss, perceptual loss, feature reconstruction loss, style reconstruction loss, gram matrices,Deepfake,face de-identification, video translation]
toc : true
math : true
---

# 강의 복습 내용

- instance segmentation
  - mask r-cnn
    - roialign
  - YOLACT
  - YolactEdge
- panoptic segmentation
  - UPSNet
  - VPSNet
- Landmark localization
- hourglass network
- dence pose
- RetinaFace
- detecting objects as keypoints
  - CornerNet
  - centerNet
- conditional generative model
  - GAN
  - super resolution
  - pix2pix
  - cycleGAN
    - cycle- consistency loss
  - perceptual loss
    - feature reconstruction loss
    - style reconstruction loss
      - gram matrices
  - Deepfake
  - face de-identification
  - video translation

## 얻은 지식

---

## instance/panoptic segmentation

### instance segmentation

- ![그림](https://user-images.githubusercontent.com/24247768/110796307-2703fc80-82bb-11eb-9e5f-1ec368a99332.png)
  - 같은 물체 클래스라도 instance에 따라 다르게 구분한다.
- 물체탐지를 기반으로 진행

#### mask R-CNN

- ![그림](https://user-images.githubusercontent.com/24247768/110796432-4a2eac00-82bb-11eb-8921-99be4745fdfa.png)
  - RoIPooling의 향상된 버전인 RoIAlign을 사용
  - pooling은 정수좌표지만, RoIalign은 소수점 레벨의 pooling이 가능하게 됨
  - faster r-cnn + mask branch
    - convolution부분은 mask branch가 추가되어있다.
- 몸의 포즈를 예측도 가능하다고 한다.

#### YOLACT

- you only look at coefficients
- ![그림](https://user-images.githubusercontent.com/24247768/110796585-75b19680-82bb-11eb-9508-998e78d13f3c.png)

#### YolactEdge

- yolact를 영상으로 확장
- ![그림](https://user-images.githubusercontent.com/24247768/110796857-c6c18a80-82bb-11eb-9c7a-3eb91ee030c2.png)

### panoptic segmentation

- ![그림](https://user-images.githubusercontent.com/24247768/110796937-e22c9580-82bb-11eb-9e59-10293a8d5d79.png)
  - 배경과 instance segmentation을 진행

#### UPSNet

- ![그림](https://user-images.githubusercontent.com/24247768/110797139-1d2ec900-82bc-11eb-819e-2e6ddc3b795b.png)
  - panoptic head는 융합
- ![그림](https://user-images.githubusercontent.com/24247768/110797225-346db680-82bc-11eb-8962-a8b082e5db3d.png)
  - instance head는 물체를
  - semantic head는 물체와 배경

#### VPSNet

- 영상특화
- ![그림](https://user-images.githubusercontent.com/24247768/110798087-25d3cf00-82bd-11eb-8e1f-c1c90f1cf401.png)

### Landmark localization

- ![그림](https://user-images.githubusercontent.com/24247768/110798300-5ae02180-82bd-11eb-86d2-d495e1624f72.png)
- 키포인트 측정, 얼굴이나 포즈 측정

#### coordinate regressiong, heatmap classification

- ![그림](https://user-images.githubusercontent.com/24247768/110799118-2c167b00-82be-11eb-898e-535de771207f.png)
  - 정리필요

#### hourglass network

- 모래시계구조
- ![그림](https://user-images.githubusercontent.com/24247768/110801661-d0012600-82c0-11eb-8306-b36e8846d043.png)
  - 내부는 unet과 유사하게생겼다.
  - concat이 아닌 더하기가 적용된다.
  - ![그림](https://user-images.githubusercontent.com/24247768/110801764-e60ee680-82c0-11eb-9ebd-20092e2255b2.png)

#### dence pose

- faster r-cnn + 3d surface regressiong branch
- ![그림](https://user-images.githubusercontent.com/24247768/110802092-35551700-82c1-11eb-869a-7c0b3266f35b.png)
- UV map
  - 3d 모델을 2차원으로 만든거

#### RetinaFace

- FPN + Multi-task branch
- ![그림](https://user-images.githubusercontent.com/24247768/110802322-6d5c5a00-82c1-11eb-852d-c85c55e82a44.png)

---

### detecting objects as keypoints

#### CornerNet

- 박스는 top-left, bottom-right를 코너로 얻어서 사용
- ![글미](https://user-images.githubusercontent.com/24247768/110802451-8d8c1900-82c1-11eb-84d2-63cd94abd03a.png)

#### centerNet

- 박스는 top-left, bottom-right에 center 추가
- ![그림](https://user-images.githubusercontent.com/24247768/110802741-ce842d80-82c1-11eb-863d-8847fb74f82a.png)
- 다른 방식으로 박스를 가로, 세로, 중앙(width,height,center)을 사용
- ![그림](https://user-images.githubusercontent.com/24247768/110802812-e3f95780-82c1-11eb-9cc4-6561f51e896b.png)

---

## Conditional Generative Model

- 주어진 조건에 맞춰 이미지를 생성하는것
- ![그림](https://user-images.githubusercontent.com/24247768/110802948-07bc9d80-82c2-11eb-9f47-38a43c85fdd3.png)
  - 가방을 스케치한것을 조건으로 가방 이미지를 생성
- 저음질 파일을 고음질 파일로 생성하는것도 가능
- GAN
  - 위조지폐법(generator), 경찰(discriminator)로 생각
- ![그림](https://user-images.githubusercontent.com/24247768/110803056-26229900-82c2-11eb-81ca-e460f2570a53.png)
  - GAN과 conditional GAN
    - D는 discriminator, G는 generator
  - c라는 조건을 입력하는게 존재

### super resolution

- 저화질->고화질 사진으로
- ![그림](https://user-images.githubusercontent.com/24247768/110803442-8c0f2080-82c2-11eb-8724-12b8486a4685.png)
- naive regression model과 차이
  - ![그림](https://user-images.githubusercontent.com/24247768/110803705-d09abc00-82c2-11eb-9866-07f136421e97.png)
  - 실제와 만든 이미지를 비교하여 loss(MAE,MSE)를 통해 비교하는식으로 진행
    - MAE
      - 정답과의 차의 절대값의 평균(l1)
    - MSE
      - 정답과 차의 제곱의 평균(l2)
- ![그림](https://user-images.githubusercontent.com/24247768/110803809-ee682100-82c2-11eb-9a18-c43587323126.png)
  - regression은 전체적으로 중간적인 결과를 만들어낸다.(파란색)
    - 어정쩡하다고한다.
    - 모두를 만족하는 평균적인 값이 나온다.
  - 반면 GAN(노란색)은 실제 이미지같은지 가짜같은지로 판단하기때문에 평균적이지않고 있을법한 이미지를 만들어준다고한다.
- ![그림](https://user-images.githubusercontent.com/24247768/110803904-06d83b80-82c3-11eb-95b0-cab52ed87987.png)
  - 흰색과 검정만 있다고 할때
  - l1은 회색을 만들어낸다.
  - GAN은 검정 또는 흰색만 보았기때문에 둘중 하나를 출력한다.

### image translation GANs

- 한 이미지를 다른 이미지 또는 다른 스타일(도메인)로 변환해준다.

#### pix2pix

- ![그림](https://user-images.githubusercontent.com/24247768/110804358-73ebd100-82c3-11eb-93e0-ec263573b75c.png)
- L1 loss와 GAN loss을 같이 사용
  - L1은 blurry하게, GAN으로 좀더 현실과 같도록
  - ![그림](https://user-images.githubusercontent.com/24247768/110804715-c4fbc500-82c3-11eb-838b-17bcddb1ada5.png)

#### cycleGAN

- pix2pix는 pairwise data이다
  - supervised하여 정답이 필요하다.
- unpaired방법은 뭐가 있을까
- loss는?
  - ![그림](https://user-images.githubusercontent.com/24247768/110805624-9c27ff80-82c4-11eb-8e8f-ca6aced5dc66.png)
  - GAN loss
  - cycle- consistency loss
- mode collapse
  - 어떤입력이든 같은 출력만 나온다.
- cycle-consistency
  - ![그림](https://user-images.githubusercontent.com/24247768/110804890-ef4d8280-82c3-11eb-9f60-fb664d901129.png)
  - x를 y로 다시 x로 왔을때 차이가 없도록 하는 것

### perceptual loss

- GANloss
  - 학습이 어렵고 코딩이 필요
  - 사전학습할 필요가 없다.
  - 다양한 어플리케이션에 적용 가능
- perceptual loss
  - 학습과 코딩이 편하다.
  - 사전학습이 필요하다.
- ![그림](https://user-images.githubusercontent.com/24247768/110805873-db565080-82c4-11eb-86cc-b9ea1ea18b5c.png)
  - loss network는 고정
- feature reconstruction loss
  - ![그림](https://user-images.githubusercontent.com/24247768/110806256-38ea9d00-82c5-11eb-9063-beb77b239524.png)
  - transformed image가 content target(원본)을 잘 유지하고있는지 보는것
  - vgg가 feature를 뽑아준다.
  - 두 결과를 비교하여 loss를 계산(l2)
  - 인식된 두결과가 같은것을 인식해야한다.
- style reconstruction loss
  - ![그림](https://user-images.githubusercontent.com/24247768/110806334-50c22100-82c5-11eb-9198-533a86bc4d46.png)
  - transfored image가 style target과 같은 스타일인지 판별
  - style을 알기위해 gram matrices를 사용
    - 채널x채널로 만들어주느것
    - 공간의 대한 정보를 제외해줘야한다.

### Various GAN application

- Deepfake
  - 음성이나 얼굴을 다른 음성이나 얼굴로 변환
  - 윤리문제로 deepfake찾기 챌린지도 있다.
- face de-identification
  - 얼굴인식 저하
  - privacy를 방지하기위해 얼굴인식을 저하해준다.
  - 특정 비밀번호를 쳐야 얼굴을 제대로 인식하는 방식으로도 사용
- video translation
  - 비디오를 게임으로사용
  - 포즈를 변환

---

## 좀더 찾아보기

- gram matrice
- roipool과 roialign
- coordinate regressiong, heatmap classification

---

## 피어세션 정리

- 내일 2시부터 3시
- 내일 준호님 참여 힘듬

### 과제

- setattr

## 과제 설명

- 공지
  - 일부 문제에서 잘못된 공지가 있었다.
  - 답이 다른게 나오는경우가 있다.

### 조교님

- 최동민조교님
  - 비전
  - 네트워크 구성, task를 어떤방법으로 풀지를 조사하는데 관심있다.
  - 네트워크를 개발하기보단, semi supervised learning으로 segmentation하는 연구

### 기타질문

- Mask R-CNN 에서 Mask layer의 역할이 같은 class의 instance 들을 분리하는 걸로 이해해도 될까요?
  - mask는 시그멘테이션이 roi에서 binary형태로 진행
  - 개랑 고양이를 구분할때 개, 고양이 마스크를 진행하는게 아닌
  - binary로 배경인지 물체인지를 본다.
  - 물체에대한 classification을 하는게 아니다.
- grad cam에서 relu쓴 이유가 뭘까요
  - relu는 +만 보기때문에 긍정적인것을 보려고한다.
- 1 x 1 convolution layer와 global average pooling의 장점이 입력 이미지에 상관없이 네트워크를 학습할 수 있다라는 얘기를 많이 들었는데 최근의 알고리즘 코드보면 여전히 입력 이미지 Resize를 계속하는데 이유가 있을까요?
  - 큰이미지에대해 된다고 해도, 실제로 학습할때 메모리 부족이있다.
  - 큰이미지를 돌려서 결과를ㄹ 낼수있다.
  - roi가 엄청많아져서 메모리 터지수러있다.
  - 특정사이즈를 학습할때 괜찮은 결과가 나오기도 했다고 한다.
- RoI Align에서 이미 instance 별로 분리가 된 상태로 넘어가는 것 같은데, 그러면 Mask R-CNN을 따로 다룰 만큼 중요하게 여기는 이유가 "RoI Align + R-CNN"과 동일한 task와 원리를 가지고 단지 Mask layer를 추가적으로 활용해 성능만 높아진 것 때문인가요?
  - faster과 mask의 차이는 task차이
  - faster는 물체 탐지, mask는 더 나아가 instance segmentation
  - roi pooling을 썻지만 roi align을 써서 예측된 roi를 넘길때 정교하게 넘어가준 중요한 부분
  - 1 mask가 중요한 이유는 instance segmentaion 성능이 좋다.
  - 2 좋은 모델로 알려진 faster에서 mask브랜치를 추가하니까 복잡한 task를 해줘서
  - panoptic이 좀더 복잡하고 새로운 task여서 옛날보단 위상이 떨어졌다.
- Stacked Hourglass Network는 키포인트 추정 알고리즘에서 ResNet처럼 대중적으로 쓰이는 backbone으로 알고있는데 구조가 FPN과 매우 유사해보입니다. Hourglass Network와 FPN의 차이가 무엇인지 또 특히나 키포인트 추정에서 성능이 뛰어난 이유가 궁금합니다!
  - unet이나 hour glass나 FPN은 생긴건 비슷해보이고 세부가 약간 다름
  - 정확히 어떤게 FPN이고 아니다가 쉽지 않다
  - FPN은 네트워크가 피라미드처럼 생기면 FPN hourgrass가 FPN이냐 하면 혼동이도니다.
  - fpn은 여러가지 task를 푸는 back본으로 사용 멀티스케일에 효율이 좋다.
    - 중간 레이어마다 사용
    - 사람얼굴 찾을때 사람 얼굴크기가 다르다.
  - hour glass는 입력이 고정, 고정된거만큼 예측
    - 사진안에 있는 랜드마크를 정확히, 정확도에 집중
- DensePose 모델의 경우 2차원 이미지를 입력으로 받아서 출력하는건데 출력 이미지를 보면 3차원으로 해석하는 것 처럼 보입니다. 진짜 3차원 정보를 담고있는건지 아니면 그림만 그럴듯하고 2차원 정보만 담고있는건지.. 또 U랑 V 데이터는 어떻게 해석해야 할지 잘 모르겠습니다.
  - 풀고자 하는 task가 2디일때 사람의 대한 3차원정보를 찾느거
  - 말하는것처럼 이해하심 됨
  - 사람은 이미지를 보면 기존 경험으로 3차원을 예측한다.
    - 이런 사람이 하는 능력을 네트워크로 표현했다고 이해하면 된다.
- Grad-CAM에서 weight 구할 때 왜 gradient를 활용하나요? gradient가 큰거랑 네트워크가 집중하는 부분이랑 무슨 상관인지 궁금합니다.
  - gradient가 크면 이부분이 결과를 결정하느네 크다, 집중을 했다는 의미
  - 모델을 해석할때 대부분 이런 컨샙을 응용
- [weakly-supervised learning](https://hbilen.github.io/wsl-eccv20.github.io/)
- ResNet의 Skip connection을 보면 ResNet 논문에서는 잔차만을 학습시켜서 학습의 복잡도를 줄여준다고 설명되어있지만 FPN이나 UNet에서 사용하는 것처럼 이미지 resolution이 뛰어난 feature map과 semantic feature가 뛰어난 feature map을 더해줌으로서 resolution을 보정해주는 효과가 있는 것처럼 보이기도 하는데 잘못된 해석일까요?
  - reolution보정
  - fpn과 unet
    - unet인 인코더, 디코더이며 인코더를 디코더로 넘겨준다.
    - 인코더를 거칠수록 feature가 추상적이고 global해진다.
    - 그대로 decoder로 하면 경계를 잘 찾기 어려워서 좀더 local한 정보를 따로 받아서 사용한다.

### 질문

- nn.parameter
  - conv layer의 weight를 뽑을때 쓰는것
- autograd에서 hook에서 input grad와 output grad 차이
  - layer에 입력과 출력에 있을때
  - input의 grad와 output의 grad를 뽑을 수 있다.
- layer1의 output grad와 layer2의 input grad가 같은지?
  - 연결되어있으면 같을텐데 분기가 생긴다면 달라질수 있다고 한다.
- 3번의 5-4에서 backward score를 구해야 할지?
- register_hook으로, hook_func을 전달한다고 했을때hook_func의 아규먼트는 기본적으로 (self, input, output)으로 구성해야한다고 하셨습니다.이 hook_func가 호출될때 input과 output에는 어떤 값이 들어가는 것인가요?
- register_forward_hook 이랑 register_hook 은 다르지않나요??
  - [참고](https://pytorch.org/docs/stable/autograd.html?highlight=register_hook#torch.Tensor.register_hook)
- (2) Forward pass to hook features 전에 (3) Register hook for storing gradients 실행되게 순서를 바꿔야 save_grad에 정상적으로 값이 들어가던데, 이렇게 해야하는 게 맞을까요?
  - layer에 hook을 할지 forward에 hook을 할지에 따라 결과가 달라진다고 한다.
- 모델 레이어에다가 register_backward_hook 하는게 문제의 의도가 아니었고 텐서에다가 register_hook 하는게 문제의 의도였을까요?
  - 문제의도는 둘다였다.
- Assignment2에 copy_last_layer 부분에서 bias를 copy하는 것이 영향이 있나요?
  - 영향이 없다.
  - bias부분에 맞게 copy를 해줘야한다.
- 최종적으로 grad_CAM은 채널이 1개짜리인 이미지형태인데, 시각화 했을때 어떻게 컬러처럼 보이는 것일까요?
  - heatmap으로 뽑아서 특정 컬러로 처리해준거
  - `plt.imshow(grad_CAM, cmap='jet', alpha = 0.5)`
- grad cam
  - discussion을 보기
  - 2번문제와 연관되어있다.
- 과제 3 Todo-1에서 param.shape을 찍어보면 3차원인것(h, w, d)도 있고 그냥 1차원인것도 있는데 3차원인거만 생각해서 h*w*d구하고 다 더해줘야되나요?
  - 모듈이 들어갔을때 파라메터갯수를 주는거므로 다 곱해주면된다고한다.
- 과제 3 TODO5-3에서 back hook을 TODO5-1에서처럼 특정 계층에만 걸어줘야 하나요? 아니면 여러 계층에 걸어줘야 하나요?
  - 문제를 풀때는 특정계층 한번만 걸어도 풀 수 있을것이다.
  - back hook없이도 가능할거다\
