---
layout: post
title: 34.multimoda과 3d물체
categories: AI boost
tags: [ai,boost,multimodal,joint embedding,cross modal translation, metric learing, cross modal reasoning, show and tell, show attend and tell, text to image by generative model, visual question answering, audio,spectrogram, STFT,short time fourier transform,melspectrogrma,MFC,soundnet,speech2face,image-tospeech,sound source localization,looking to listen at the cocktail party, lib movements generation,3d,3d물체인식,3d recognition, 3d semantic segmentation, mesh r-cnn,3d 데이터셋,shapeNet,partnet,scenenet,scannet,outdoor 3d scene datasets]
toc : true
math : true
---


# 강의 복습 내용
- multimodal
  - visual data and text
    - joint embedding
      - image tagging
        - metric learning
    - cross modal translation
      - image captioning
        - show and tell
        - show attend and tell
        - text to image by generative model
    - cross modal reasoning
      - visual question answering
  - visual data and audio
    - audio 처리
      - spectrogram
      - Fourier trasform
        - STFT(short time fourier transform)
      - melspectrogrma
      - MFC
    - join embedding
      - soundnet
    - cross modal translation
      - speech2face
      - image-tospeech
      - sound source localization
      - looking to listen at the cocktail party
      - lib movements generation
- 3d
  - 데이터형식
    - multi-view images
    - volumetric(3d공간을 픽셀처럼 생각)
    - part assembly(작은 부품의 집합)
    - point cloud(3d포인트의 집합)
    - mesh(graph cnn에 사용,vertex와 edge의 형태로 삼각형모양)
    - implicit shape(고차원의 함수 형태)
  - 데이터셋
    - shapeNet
    - partnet
    - scenenet
    - scannet
    - outdoor 3d scene datasets
  - 3d task
    - 3d recognition
    - 3d semantic segmentation
    - conditional 3d generation
      - mesh r-cnn

## 얻은 지식

-----

## multimodal:captioning and speaking
- 한데이터뿐만아니라 다른 데이터도 같이 학습하는것

-----

### multimodal 이란?
- unimodal
  - 하나의 데이터형식으로 학습하는것
- multimodal
  - 다중감각
  - 동시에 여러 감각기관으로 학습하는것
  - 시각 + 청각
- 서로다른 modal끼리 차이
  - 데이터형식 
  - 매칭의 불균형
  - 학습시 쉬운 특정 modal에 bias된다.

-------

### visual data and text
- text data는?
  - text embedding을 사용
  - ![그림](https://user-images.githubusercontent.com/24247768/111450271-94001200-8753-11eb-8ce9-e08d01d84d2a.png)
- word2vec
  - skip-gram model
  - 하나의 단어가 들어오면 앞 뒤로 올 단어들을 예측하는것을 학습


#### joint embedding
- 공통된 embedding을 학습
- image tagging
  - 이미지에 태그를 추천
  - 태그로부터 이미지를 찾기 
  - 사전에 학습된 unimodal 모델을 결합
    - ![그림](https://user-images.githubusercontent.com/24247768/111450402-b09c4a00-8753-11eb-9e18-3db8c1de84b9.png)
  - 학습하는 방식 metric learning
    - ![그림](https://user-images.githubusercontent.com/24247768/111450466-c27ded00-8753-11eb-9d79-ab766c3b4fbb.png)
    - 매칭되는 pair에 대해서는 embedding space의 간격을 줄이는방향으로
    - 매칭이 안되면 간격을 넓히는 방향으로 학습
    - space는 이미지와 text둘의 정보를 가지게된다.
  - 이미지와 text 의 관계를 embedding이 학습을 하게된다.
    - multi modal analogy를 학습한다.
    - 강아지사진 - 강아지 + 고양이 = 고양이 사진이 나온다.
    - ![그림](https://user-images.githubusercontent.com/24247768/111450946-3fa96200-8754-11eb-9317-cc7988756e7f.png)
- image & food recipe 연결도 가능
  - 이미지를 입력하면 재료를 출력, 재료를 입력하면 이미지를 출력
  - 레시피는 순서가 있어야 하므로 rnn으로 제작

#### cross modal translation
- image captioning
  - show and tell
    - 이미지를 입력하면 이미지를 표현하는 텍스트를 출력
    - image는 cnn, 텍스트는 rnn
    - 인코더(cnn), 디코더(lstm)
      - ![그림](https://user-images.githubusercontent.com/24247768/111451131-74b5b480-8754-11eb-9cdc-fffe6d5fc725.png)
      - 이미지를 입력하여 cnn을 통해 featrue 추출
      - 추출된 featrue를 lstm을 통해 텍스트로 변환
  - show attend and tell
    - 집중하는 attention을 추가
    - ![그림](https://user-images.githubusercontent.com/24247768/111451292-9fa00880-8754-11eb-9d6c-83ce7c4dfe82.png)
      - 여자와 프리스비를 집중하여 보여준다.
    - ![그림](https://user-images.githubusercontent.com/24247768/111451374-b8a8b980-8754-11eb-9bc7-e76eb170c17b.png)

  - text to image by generative model
    - 텍스트로 이미지를 생성모델로 생성
    - generator(conditional GAN 텍스트로 이미지 만들기), discriminator(이미지와 텍스트를 매칭하도록 학습)
    - ![그림](https://user-images.githubusercontent.com/24247768/111451523-dd049600-8754-11eb-8410-6eda8e0952db.png)

#### cross modal reasoning
- 다른 모달을 참조해서 결과를 도출하는것
- visual question answering
  - 이미지와 질문이 주어지면 답을 도출
  - qeustion은 lstm, 이미지는 cnn
  - ![그림](https://user-images.githubusercontent.com/24247768/111451678-07eeea00-8755-11eb-8fbb-8707a54ad521.png)
  - 전체적으로 end-to-end로 학습이 진행

-------


### visual data and audio
- 사운드를 어떻게 표현?
  - ![그림](https://user-images.githubusercontent.com/24247768/111451801-281ea900-8755-11eb-8b85-fd2634076b93.png)
  - 사운드는 시간축을 기준으로 신호(waveform)로 존재
  - 머신러닝에서 사용하기 위해서는 acoustic feature인 spectrogram으로 변환해야한다.
    - spectrogram이란?
    - 이미지변환
  - Fourier trasform
    - STFT(short time fourier tranform)
    - ![그림](https://user-images.githubusercontent.com/24247768/111452052-72078f00-8755-11eb-8491-cf293ecffee8.png)
      - 윈도우사이즈씩 적용
  - 타임축 기준으로 쌓는다.
    - ![그림](https://user-images.githubusercontent.com/24247768/111451916-4ab0c200-8755-11eb-9f84-dca06bdbcd75.png)
  - melspectrogrma
  - MFC

#### joint embedding
- soundnet 
  - autio representation을 비디오의 한 프레임에 맞춰 학습
    - teacher-student 학습을 진행
  - ![그림](https://user-images.githubusercontent.com/24247768/111452160-95cad500-8755-11eb-8a6c-4a93fbea3fd8.png)
  - 영상에서 음성은 row waveform을 이용
  - 각 프레임마다 이미지 인식 진행
    - 물체인식과 장면인식을 오디오쪽 cnn을 학습시킨다.

#### cross modal translation
- speech2face
  - ![그림](https://user-images.githubusercontent.com/24247768/111452259-ad09c280-8755-11eb-8423-3aa9e01e13b7.png)
  - 음성을 통해 얼굴을 상상하는것
  - module networks
    - 얼굴인식모듈(vgg face model)을 미리 학습
    - face decoder라는 얼굴 feature가 오면 정면의 얼굴을 출력하는 모듈
  - speech2face model의 feature가 얼굴인식 feature를 따라가도록 학습을 진행
- image-tospeech
  - 이미지로부터 음성을 만들기
  - ![그림]
  - 이미지 입력으로 unit 추출, unit으로 음성 출력
    - 두 부분으로 나눠서 학습을 진행
    - 한번에 학습이 되는건 아니라고 한다.
- sound source localization
  - 영상에서 음성이 어디서 나는지 보여주기
  - ![그림](https://user-images.githubusercontent.com/24247768/111452356-c743a080-8755-11eb-8c7e-4e3f1021f174.png)
  - 이미지 프레임과 오디오가 입력
    - supervised loss 로 정답위치를 제공해줘야한다.
- looking to listen at the cocktail party
  - 여러 인물이 말할때 특정 사람의 인물의 음성만 듣기
  - ![그림](https://user-images.githubusercontent.com/24247768/111452482-ea6e5000-8755-11eb-8152-23db81004d91.png)
  - 학습시에는?
    - 이미 음성이 섞여서 학습이 어렵다.
    - 두개의 영상파일을 합쳐서 각각의 label를 이용하여 학습을 진행
- lib movements generation
  - 음성파일로 입술의 움직임을 만들기


## 3d
- 실세계는 3d로 이뤄져있다.
  - vr/ar활용
  - 의학의 분자구조
- 3d는 2d로 인식이된다.(projection)
- 두개의 view로 3d로 변환이 가능하다.
  - multiple view geometry
- 표현은?
  - 2d는 각 픽셀별로 값을 가진다.
  - ![그림](https://user-images.githubusercontent.com/24247768/111452604-096ce200-8756-11eb-9240-0b17ae790f31.png)
    - multi-view images
    - volumetric(3d공간을 픽셀처럼 생각)
    - part assembly(작은 부품의 집합)
    - point cloud(3d포인트의 집합)
    - mesh(graph cnn에 사용,vertex와 edge의 형태로 삼각형모양)
    - implicit shape(고차원의 함수 형태)
- 데이타셋
  - shapeNet
  - partnet
    - 물체의 부품별로 구분
  - scenenet
    - 방의 이미지
  - scannet
    - 실제 방을 스캔
  - outdoor 3d scene datasets
    - 자율주행관련
    - kitti, semantic kitti, waymo open dataset

### 3d task

#### 3d recognition
- 3d물체 인식, detection 등
- ![그림](https://user-images.githubusercontent.com/24247768/111452946-610b4d80-8756-11eb-8c6e-5cdd905ae0ca.png)
- 3d cnn(volumetric cnn)을 이용

#### 3d semantic segmentation
- ![그림](https://user-images.githubusercontent.com/24247768/111453023-78e2d180-8756-11eb-840d-6a930e9494b4.png)
- 각 파트별로 segmentation

#### conditional 3d generation
- mesh r-cnn
  - 2d이미지->3d mesh로 물체인식을 한다.
  - ![그림](https://user-images.githubusercontent.com/24247768/111453461-f1e22900-8756-11eb-8652-6bad8a0478eb.png)
    - mask r-cnn에 3d branch를 추가한 형태

### 3d application 예제
- 포토 리포커싱
  - ![글미](https://user-images.githubusercontent.com/24247768/111453621-1c33e680-8757-11eb-893e-e6de63b05bb4.png)
  - 특정 물체만 포커싱하고 나머지는 날려주는 효과


----

## 좀더 찾아보기
- melspectrogrma
- MFC
- spectrogram


-----


## 피어세션 정리
- spectrogram
  - 이미지처럼 변형
  - 의미이면 rnn, 음성의 특징은 spectrogram




-----

## 마스터클래스
- 어느정도의 논문 이해수준
  - 너무많은 논문이 있었다.
  - 전반적인 입력과 출력, 모델의 큰 그림을 보여주고 싶었다.
  - 코드의 블럭을 보고 모델의 구조를 파악하는 정도를 알 수 있게
    - 코드로 수정이 가능하도록
- 회사가 원하는 능력은?
  - 회사의 기준에 따라 다르다.
  - 꼼꼼함이 필요
- transformer의 전망은?
  - 데이터가 많은면 transformer가 잘되는걸 많이 보여줌
- 데이터가 많은 기준은?
  - 오버피팅이되는것을 기준이라 생각
- c언어와 python
  - c가 좀더 빨라서 서비스에 사용된다고한다.
  - 자동으로 python에서 c로 컨버트해주는게 있다.
- 마지막은?
  - 영어를 배워라!
  - 자신만의 기준을 만들고 감을 익혀라!



## 후기
- 전체적으로 어려운 분야였다.
- 한 강의에서 많은 논문을 다루다보니 전체적으로 입력과 출력과 특징만 알고 넘어가게되었다.
- 아무래도 transformer가 많은 연구에 큰 영향을 주었나보다.


