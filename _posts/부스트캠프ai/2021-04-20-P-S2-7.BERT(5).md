---
layout: post
title: P-S2-7.BERT(5)
categories: AI boostP
tags: [ai,boost]
toc : true
math : true
---

## 강의확인

### 문장 토큰 분류
- 주어진 문장의 각 token이 어떤 범주에 속하는지 분류
- named entity recognnition(NER)
  - 특정한 의미를 가지는 단어를 인식             
  - 개체명, 인명, 날짜, 기관명 등 
- part-of-speech tagging(POS tagging)
  - 품사단위로 태깅
- 데이터
  - kor_ner
    - bio태그

------

## 피어세션
- Stratified KFold, 앙상블을통해 성능향상이 있었다고한다.(2등!)
  - 메모리누스는 폴더에 저장하는 방식?
- 입력sentence를 concat하여 증가시키니 성능이 오르긴했다.
- 임베딩 레이어에 리사이즈가 필요
- 멀티센텐스가 더 좋았다.


## 오피스아워 text augmentation(박상희님)
- text augmentation이란?
  - 부족한 데이터 증강
- 꽤어려움
  - 의미보존, 외적인구조만 변경, 의미 정의가 어렵고, 제대로 되어있는지 판단이 어려움
- EDA(easy data augmentation)
  - 전처리 기법으로 augmentation
  - 50% 데이터로 전체데이터와 같은성능
  - 논문에서는 4가지방법
  - SR,RI,RS,RD
- back trasnlation
  - 기계번역의 성능을 향상시키기위해
  - 한국-번역-외국어-번역-한국어 를 사용
- transformer

### QA
- 포트폴리오
  - 구심점이 필요
  - 하나를 집중해서 진행
  - 문제제기, 기존한계, 해결과정
- 토크나이저나 언어모델은 특정 도메인에 맞게 직접 만들기도한다.
- hugging-face사용하는것을 아는것도 장점이될수있다.
  - fairseq는 카카오 브레인에서 사용한다.

------

## 오늘 한일
- 토큰 추가하여 학습 진행


## 어떻게 했는지
- `cls단어1 sep단어2sep문장`의 형태에서 `cls문장e1단어e1문장e2단어e2문장`형태로 변형하여 학습
  - 앞에서 단어를 표시해도 문장에서 토큰화되면서 제대로 표시를 못하는 경우가 있었다.
    - '자동차'라는 단어가 문장에서는 '자동차의'로 되면서 토큰나이저가 다르게 잘라낸다.
  - 이를 위해 그냥 문장에서 직접 해당 단어들에 토큰으로 감싸서 사용
- 하나의 문장보다 두개의 문장을 이용
  - `cls단어1 sep단어2sep문장e1단어e1문장e2단어e2문장`으로 적용하여 학습
  - 아무래도 단어에대한 정보를 좀더 나타내서 성능이 올랐다고 생각합니다.


## 좋았던 점
- 약간의 성능향상을 기대했는데 실제로 성능이 올랐습니다.


## 아쉬운 점
- 좀더 많은 시도를 해보고싶은데 코드의 이해와 어떻게 적용하는지에대한 고민이 오래걸려서 아쉽습니다.
